{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach 1.1:**\n",
    "\n",
    "**Training:**\n",
    "\n",
    "-> For every selected frame of video, extract features and give label(label generated by converting manually marked safe duration into frame intervals)\n",
    "\n",
    "-> Use classification to predict 0/1 for each frame\n",
    "\n",
    "**Testing :**\n",
    "\n",
    "For every frame, extract features and use classification to predict label\n",
    "\n",
    "**Features to be extracted from individual frames:**\n",
    "\n",
    "1. Number of bounding boxes in every region (total region:6)\n",
    "2. Total Area covered by all bounding boxes in every region\n",
    "3. Minimum distance of bounding box from every region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline  \n",
    "from imageai.Detection import VideoObjectDetection\n",
    "import os\n",
    "import sys\n",
    "from random import randint\n",
    "from math import ceil, sqrt\n",
    "import natsort\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sys\n",
    "import cv2\n",
    "from random import randint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'yagnesh'\n",
    "\n",
    "if name == 'siddhi':\n",
    "    path_train_arrays = '/home/siddhi/Desktop/RoadCrossingAssistant_FY_Project_Data/arrays_train_v2'\n",
    "    path_test_arrays = '/home/siddhi/Desktop/RoadCrossingAssistant_FY_Project_Data/arrays_test_v2'\n",
    "    path_train_labels = '/home/siddhi/Desktop/RoadCrossingAssistant_FY_Project_Data/labels_train.csv'\n",
    "    path_test_labels = '/home/siddhi/Desktop/RoadCrossingAssistant_FY_Project_Data/labels_test.csv'\n",
    "    path_train_videos = '/home/siddhi/Desktop/RoadCrossingAssistant_FY_Project_Data/videos_train'\n",
    "    path_test_videos = '/home/siddhi/Desktop/RoadCrossingAssistant_FY_Project_Data/videos_test'\n",
    "\n",
    "\n",
    "elif name == 'yagnesh':\n",
    "    path_train_arrays = '/home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train'\n",
    "    path_test_arrays = '/home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_test'\n",
    "    path_direction_train_arrays = '/home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/directions_train'\n",
    "    path_direction_test_arrays = '/home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/directions_test'\n",
    "    path_train_labels = '/home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/labels_train.csv'\n",
    "    path_test_labels = '/home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/labels_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for distance calculation for every region\n",
    "bottom_center_point_x = 1920/2    # width/2\n",
    "bottom_center_point_y = 1080      # height\n",
    "cx = 1865\n",
    "cy = 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "67, 356, 1046, 611], [1447, 508, 1753, 767], [951, 526, 1174, 719], [173, 513, 576, 854], [1395, 485, 1536, 652], [40, 373, 325, 537], [1697, 595, 1912, 1080]])\n list([[692, 360, 1030, 602], [1444, 515, 1745, 768], [897, 523, 1145, 722], [117, 529, 534, 855], [39, 385, 310, 530], [1695, 594, 1912, 1080]])\n list([[717, 358, 1018, 601], [1432, 515, 1743, 771], [882, 531, 1128, 732], [64, 517, 490, 851], [33, 384, 311, 528], [1692, 593, 1912, 1080]])\n list([[731, 358, 1104, 609], [30, 522, 420, 866], [853, 529, 1104, 732], [39, 374, 287, 535], [1693, 596, 1911, 1080]])\n list([[745, 362, 1103, 599], [1422, 531, 1735, 773], [827, 536, 1076, 740], [5, 523, 396, 864], [1356, 480, 1510, 657], [1693, 604, 1911, 1080]])\n list([[263, 485, 516, 651], [0, 579, 330, 863], [798, 524, 1061, 738], [45, 369, 329, 534], [1691, 605, 1910, 1080]])\n list([[304, 497, 560, 653], [0, 588, 285, 865], [760, 514, 1043, 738], [45, 372, 331, 535], [1693, 610, 1911, 1080]])\n list([[332, 494, 593, 650], [0, 601, 219, 865], [724, 529, 1010, 746], [1693, 613, 1911, 1080], [55, 369, 340, 535]])\n list([[866, 394, 1247, 621], [0, 590, 167, 867], [356, 492, 638, 647], [688, 526, 992, 742], [1692, 610, 1911, 1080], [40, 377, 332, 536]])\n list([[857, 392, 1259, 622], [404, 484, 662, 644], [662, 508, 1005, 747], [1312, 471, 1474, 671], [33, 376, 327, 539], [1693, 614, 1912, 1080]])\n list([[859, 393, 1271, 615], [601, 519, 925, 751], [1283, 476, 1485, 665], [34, 375, 329, 538], [1690, 613, 1913, 1080]])\n list([[872, 402, 1278, 614], [553, 502, 889, 760], [1270, 477, 1486, 669], [35, 376, 328, 536], [1690, 616, 1913, 1080]])\n list([[873, 400, 1281, 615], [508, 493, 854, 767], [1260, 476, 1477, 663], [36, 376, 325, 534], [1691, 610, 1912, 1080]])\n list([[977, 412, 1278, 605], [475, 491, 816, 764], [1245, 476, 1470, 665], [35, 377, 328, 532], [1692, 606, 1912, 1080]])\n list([[968, 403, 1280, 603], [431, 488, 799, 765], [1693, 606, 1912, 1080], [34, 377, 328, 530]])\n list([[912, 403, 1258, 604], [391, 502, 740, 762], [34, 378, 325, 530], [1691, 604, 1912, 1080]])\n list([[973, 403, 1271, 605], [344, 429, 751, 748], [33, 377, 326, 530], [1690, 602, 1912, 1080]])\n list([[994, 401, 1264, 611], [291, 492, 660, 768], [32, 378, 328, 530], [1691, 602, 1911, 1080]])\n list([[1178, 462, 1425, 688], [1015, 404, 1249, 615], [244, 496, 612, 771], [32, 379, 328, 535], [1692, 601, 1910, 1080]])\n list([[1026, 400, 1255, 604], [200, 505, 583, 768], [36, 379, 324, 536], [1692, 599, 1910, 1080]])\n list([[1036, 404, 1262, 595], [145, 428, 544, 757], [39, 380, 325, 532], [1693, 597, 1909, 1080]])\n list([[89, 521, 475, 778], [34, 376, 339, 530], [1693, 599, 1909, 1080]])\n list([[55, 529, 432, 769], [36, 378, 298, 533], [1693, 602, 1910, 1080]])\n list([[1093, 436, 1382, 690], [11, 506, 386, 781], [41, 376, 295, 529], [1693, 602, 1909, 1080]])\n list([[1074, 442, 1369, 700], [1, 509, 339, 770], [1694, 600, 1909, 1080]])\n list([[0, 506, 289, 776], [1694, 603, 1910, 1080]])\n list([[0, 528, 248, 781], [62, 368, 327, 546], [1692, 602, 1910, 1080]])\n list([[919, 408, 1382, 706], [0, 553, 198, 765], [63, 366, 330, 537], [1690, 602, 1911, 1080]])\n list([[906, 412, 1371, 709], [0, 538, 134, 769], [69, 365, 333, 536], [1688, 601, 1909, 1080]])\n list([[901, 417, 1367, 713], [0, 508, 105, 781], [57, 366, 331, 532], [1691, 596, 1909, 1080]])\n list([[853, 424, 1321, 713], [58, 370, 332, 527], [1690, 594, 1910, 1080]])\n list([[841, 418, 1294, 721], [1, 475, 186, 620], [44, 369, 334, 522], [1689, 595, 1910, 1080]])\n list([[837, 417, 1268, 718], [11, 482, 218, 622], [55, 370, 331, 524], [1690, 597, 1909, 1080]])\n list([[28, 486, 242, 621], [52, 373, 321, 528], [1690, 596, 1908, 1080]])\n list([[783, 392, 1223, 716], [65, 483, 272, 621], [49, 370, 315, 529], [1690, 595, 1908, 1080]])\n list([[744, 385, 1205, 723], [98, 486, 315, 619], [1689, 598, 1908, 1080]])\n list([[710, 391, 1183, 722], [122, 489, 336, 622], [1691, 600, 1910, 1080]])\n list([[692, 390, 1143, 727], [2, 452, 129, 590], [144, 473, 378, 622], [1689, 604, 1911, 1080]])\n list([[186, 490, 385, 623], [4, 458, 160, 595], [1687, 605, 1911, 1080]])\n list([[210, 469, 441, 624], [15, 455, 189, 597], [1685, 605, 1910, 1080]])\n list([[44, 459, 220, 598], [253, 493, 459, 624], [45, 374, 331, 528], [1687, 605, 1909, 1080]])\n list([[67, 467, 249, 590], [288, 488, 495, 627], [48, 376, 322, 531], [1689, 604, 1909, 1080]])\n list([[92, 489, 310, 608], [299, 468, 531, 625], [44, 371, 308, 541], [1695, 601, 1909, 1080]])\n list([[340, 485, 494, 625], [119, 429, 349, 604], [1694, 600, 1908, 1080]])\n list([[156, 489, 376, 606], [1696, 606, 1909, 1080]])\n list([[194, 453, 376, 600], [30, 384, 333, 527], [1696, 610, 1910, 1080]])\n list([[223, 452, 359, 598], [29, 380, 324, 530], [1695, 610, 1911, 1080]])\n list([[32, 376, 303, 538], [1694, 610, 1911, 1080]])\n list([[37, 377, 294, 530], [1694, 611, 1912, 1080]])\n list([[1695, 614, 1912, 1080]])\n list([[44, 361, 213, 523], [1697, 616, 1912, 1080]])\n list([[615, 493, 764, 610], [1697, 620, 1912, 1080]])\n list([[597, 490, 782, 617], [1700, 616, 1912, 1080]])\n list([[622, 491, 810, 611], [1699, 615, 1912, 1080]])\n list([[654, 488, 836, 617], [1700, 615, 1912, 1080]])\n list([[487, 495, 671, 600], [667, 493, 851, 611], [1701, 614, 1913, 1080]])\n list([[527, 443, 690, 595], [705, 494, 877, 622], [1699, 616, 1913, 1080]])\n list([[560, 451, 716, 596], [721, 490, 887, 617], [1700, 613, 1913, 1080]])\n list([[749, 494, 898, 618], [1698, 613, 1914, 1080]])\n list([[1698, 613, 1914, 1080]])\n list([[635, 454, 790, 597], [1696, 611, 1914, 1080]])\n list([[653, 500, 800, 602], [1696, 609, 1914, 1080]])\n list([[37, 467, 274, 665], [1695, 609, 1914, 1080]])\n list([[66, 477, 340, 660], [1697, 608, 1913, 1080]])\n list([[116, 492, 387, 655], [1696, 605, 1913, 1080]])\n list([[171, 482, 446, 653], [1698, 605, 1913, 1080]])\n list([[220, 509, 504, 665], [1697, 607, 1913, 1080]])\n list([[282, 503, 563, 662], [1697, 606, 1914, 1080]])\n list([[336, 501, 593, 665], [1693, 604, 1914, 1080]])\n list([[1695, 606, 1913, 1080]]) list([[1692, 607, 1913, 1080]])\n list([[1692, 608, 1912, 1080]]) list([[1690, 610, 1912, 1080]])\n list([[43, 385, 266, 539], [1691, 608, 1912, 1080]])\n list([[35, 391, 296, 549], [1690, 608, 1912, 1080]])\n list([[31, 395, 314, 544], [1692, 611, 1912, 1080]])\n list([[33, 394, 329, 545], [1692, 612, 1913, 1080]])\n list([[31, 398, 335, 541], [1691, 612, 1913, 1080]])\n list([[329, 397, 612, 555], [30, 399, 332, 542], [1686, 613, 1912, 1080]])\n list([[349, 400, 644, 554], [29, 399, 332, 541], [1689, 613, 1912, 1080]])\n list([[34, 398, 330, 544], [1692, 613, 1913, 1080]])\n list([[37, 389, 319, 535], [1696, 614, 1914, 1080]])\n list([[159, 112, 1748, 1036], [39, 390, 319, 534], [1697, 613, 1914, 1080]])\n list([[511, 313, 1642, 1016], [38, 386, 323, 534], [1698, 614, 1914, 1080]])\n list([[90, 254, 1757, 1043], [1654, 534, 1725, 633], [39, 394, 319, 529], [1698, 613, 1914, 1080]])\n list([[1651, 532, 1726, 632], [33, 388, 323, 532], [1699, 613, 1915, 1080]])\n list([[1645, 531, 1721, 634], [48, 384, 342, 537], [1700, 608, 1915, 1080]])\n list([[359, 286, 1589, 1023], [1642, 532, 1722, 634], [35, 388, 313, 534], [1701, 606, 1915, 1080]])\n list([[307, 303, 1616, 1027], [1640, 533, 1723, 635], [35, 383, 311, 540], [1700, 607, 1916, 1080]])\n list([[240, 288, 1618, 1030], [1635, 533, 1722, 636], [49, 389, 304, 570], [1699, 607, 1916, 1080]])\n list([[45, 223, 1629, 1071], [1635, 533, 1724, 635], [1701, 610, 1915, 1080]])\n list([[63, 238, 1610, 1044], [1700, 614, 1916, 1080]])\n list([[50, 236, 1621, 1039], [1761, 571, 1901, 674], [1699, 614, 1915, 1080]])\n list([[27, 125, 1626, 1048], [1731, 542, 1789, 602], [1609, 515, 1695, 624], [1699, 609, 1914, 1080]])\n list([[0, 109, 1649, 1056], [1699, 607, 1914, 1080]])\n list([[0, 77, 1671, 1077], [1759, 571, 1901, 671], [1700, 612, 1914, 1080]])\n list([[1592, 525, 1708, 640], [1701, 612, 1915, 1080]])\n list([[1702, 613, 1915, 1080]])\n list([[1726, 544, 1783, 623], [1585, 521, 1708, 644], [1701, 614, 1915, 1080]])\n list([[1584, 519, 1711, 645], [1701, 615, 1916, 1080]])\n list([[363, 280, 1540, 1053], [1543, 563, 1621, 707], [1699, 615, 1916, 1080]])\n list([[405, 297, 1515, 1032], [1543, 570, 1621, 711], [77, 390, 338, 561], [1700, 614, 1916, 1080]])\n list([[404, 276, 1511, 1047], [1542, 598, 1614, 716], [76, 394, 330, 556], [1699, 613, 1916, 1080]])\n list([[397, 290, 1473, 1036], [1536, 602, 1610, 724], [1762, 576, 1906, 677], [65, 395, 323, 558], [1699, 610, 1916, 1080]])\n list([[385, 317, 1485, 1044], [1530, 601, 1608, 726], [1762, 577, 1908, 679], [1699, 613, 1917, 1080]])\n list([[204, 324, 1486, 1045], [1527, 600, 1607, 729], [1762, 580, 1908, 680], [1698, 616, 1916, 1080]])\n list([[200, 310, 1449, 1046], [1523, 604, 1607, 733], [1712, 558, 1792, 640], [1764, 580, 1908, 683], [1696, 618, 1917, 1080]])\n list([[186, 307, 1411, 1055], [1515, 597, 1605, 740], [1710, 559, 1789, 641], [45, 409, 213, 561], [1763, 583, 1905, 685], [1697, 619, 1917, 1080]])\n list([[153, 319, 1419, 1046], [1510, 592, 1600, 746], [1706, 561, 1787, 642], [1765, 585, 1903, 686], [1694, 621, 1918, 1080]])\n list([[145, 301, 1419, 1056], [1498, 593, 1595, 754], [1705, 563, 1787, 647], [1760, 584, 1907, 691], [1693, 621, 1918, 1080]])\n list([[30, 286, 1375, 1063], [1494, 600, 1595, 756], [1703, 565, 1785, 649], [1694, 619, 1919, 1080]])\n list([[1551, 537, 1679, 674], [32, 287, 1363, 1059], [1492, 626, 1583, 758], [1759, 586, 1908, 693], [1701, 565, 1783, 649], [1697, 619, 1918, 1080]])\n list([[0, 303, 1384, 1051], [1487, 623, 1577, 761], [1758, 587, 1908, 694], [1697, 620, 1919, 1080]])\n list([[1543, 535, 1677, 678], [64, 285, 1352, 1053], [1481, 620, 1577, 766], [1758, 588, 1906, 693], [1699, 621, 1919, 1080]])\n list([[50, 309, 1357, 1054], [1474, 616, 1576, 774], [1547, 549, 1680, 685], [1758, 588, 1908, 693], [1704, 577, 1779, 662], [1698, 627, 1920, 1080]])\n list([[26, 302, 1334, 1041], [1467, 620, 1573, 778], [1542, 545, 1681, 690], [1705, 579, 1780, 662], [1756, 590, 1912, 694], [1701, 631, 1920, 1077]])\n list([[3, 321, 1319, 1053], [1463, 619, 1572, 779], [1705, 579, 1780, 662], [1757, 588, 1911, 695], [1700, 630, 1920, 1077]])\n list([[11, 322, 1297, 1044], [1460, 625, 1559, 778], [1704, 578, 1781, 661], [1529, 546, 1685, 689], [1757, 589, 1910, 693], [1701, 626, 1920, 1079]])\n list([[10, 307, 1280, 1064], [1457, 626, 1556, 779], [1703, 577, 1780, 661], [1528, 545, 1684, 690], [1759, 588, 1908, 693], [1702, 626, 1920, 1079]])\n list([[0, 308, 1275, 1080], [1448, 623, 1549, 782], [1522, 544, 1680, 690], [1692, 577, 1770, 658], [1756, 586, 1907, 694], [1703, 625, 1920, 1080]])\n list([[0, 300, 1275, 1078], [1434, 629, 1549, 780], [1755, 584, 1906, 696], [1691, 578, 1771, 658], [1703, 625, 1920, 1080]])\n list([[0, 310, 1247, 1066], [1428, 628, 1540, 780], [1757, 585, 1906, 695], [1691, 577, 1768, 658], [1701, 622, 1920, 1080]])\n list([[0, 297, 1224, 1078], [1415, 624, 1533, 790], [1756, 586, 1908, 692], [1688, 577, 1768, 657], [1695, 617, 1918, 1080]])\n list([[37, 267, 1196, 1055], [1409, 627, 1528, 786], [1686, 577, 1766, 657], [1694, 616, 1917, 1080]])\n list([[1502, 527, 1657, 683], [62, 281, 1178, 1052], [1393, 634, 1519, 784], [1693, 615, 1916, 1080]])\n list([[115, 307, 1146, 1051], [1382, 628, 1510, 791], [1754, 586, 1909, 686], [1693, 613, 1915, 1080]])\n list([[12, 328, 1081, 1053], [1369, 624, 1501, 798], [1489, 542, 1660, 691], [1681, 576, 1759, 658], [1693, 614, 1917, 1080]])\n list([[15, 312, 1051, 1059], [1357, 628, 1499, 794], [1681, 577, 1758, 659], [1486, 542, 1658, 692], [1692, 615, 1917, 1080]])\n list([[17, 314, 1016, 1048], [1023, 546, 1148, 652], [1345, 604, 1487, 797], [1681, 575, 1757, 659], [1481, 541, 1655, 693], [1694, 615, 1916, 1080]])\n list([[0, 316, 1001, 1051], [1337, 603, 1483, 797], [1752, 587, 1910, 685], [1681, 573, 1758, 660], [1475, 540, 1658, 693], [1695, 615, 1918, 1080]])\n list([[0, 313, 954, 1053], [1321, 605, 1471, 810], [1675, 560, 1758, 657], [1750, 585, 1909, 687], [1473, 533, 1658, 679], [1695, 616, 1916, 1080]])\n list([[0, 312, 866, 1046], [1065, 557, 1188, 649], [1311, 614, 1467, 812], [1673, 561, 1758, 658], [1750, 584, 1908, 687], [1468, 533, 1656, 679], [1694, 616, 1916, 1080]])\n list([[0, 296, 840, 1068], [1295, 604, 1459, 815], [1671, 562, 1758, 657], [1462, 531, 1658, 678], [1749, 584, 1908, 687], [1694, 618, 1916, 1080]])\n list([[12, 286, 770, 1056], [1280, 612, 1444, 816], [1671, 561, 1758, 657], [1461, 528, 1656, 678], [1749, 584, 1910, 687], [1695, 621, 1917, 1080]])\n list([[1271, 613, 1431, 817], [1457, 524, 1658, 676], [1667, 560, 1758, 658], [1750, 584, 1908, 685], [1693, 618, 1917, 1080]])\n list([[1255, 608, 1423, 819], [1437, 525, 1652, 677], [1664, 560, 1758, 658], [1749, 583, 1909, 685], [1695, 617, 1916, 1080]])\n list([[581, 532, 763, 667], [1221, 612, 1424, 829], [1664, 560, 1757, 658], [1432, 528, 1651, 678], [1748, 583, 1909, 685], [1696, 617, 1916, 1080]])\n list([[565, 520, 803, 668], [1208, 614, 1426, 836], [1663, 560, 1755, 659], [1428, 536, 1647, 699], [1747, 584, 1910, 686], [1696, 618, 1916, 1080]])\n list([[631, 522, 822, 671], [1185, 619, 1417, 832], [1748, 584, 1909, 686], [1660, 561, 1755, 660], [1426, 538, 1647, 697], [1698, 618, 1916, 1080]])\n list([[665, 529, 856, 672], [1172, 625, 1399, 843], [1423, 535, 1647, 701], [1661, 573, 1754, 662], [1750, 583, 1907, 687], [1698, 621, 1918, 1080]])\n list([[572, 505, 719, 620], [702, 530, 894, 673], [1155, 624, 1390, 847], [1749, 587, 1908, 689], [1419, 536, 1644, 702], [1662, 573, 1754, 665], [1698, 621, 1919, 1080]])\n list([[740, 533, 908, 668], [1136, 632, 1364, 856], [1752, 587, 1908, 691], [1661, 573, 1754, 665], [1412, 538, 1644, 702], [1699, 621, 1918, 1080]])\n list([[607, 498, 769, 621], [1124, 634, 1360, 858], [1752, 587, 1908, 692], [1661, 572, 1754, 667], [1406, 537, 1642, 703], [1700, 622, 1920, 1080]])\n list([[1094, 654, 1350, 882], [1748, 589, 1912, 692], [1662, 572, 1755, 668], [1404, 537, 1639, 706], [61, 406, 295, 574], [1703, 626, 1920, 1079]])\n list([[646, 495, 788, 616], [1069, 649, 1341, 888], [1752, 590, 1910, 694], [1662, 572, 1752, 669], [1404, 537, 1638, 708], [49, 414, 313, 571], [1705, 628, 1920, 1079]])\n list([[1045, 639, 1334, 899], [1755, 591, 1907, 694], [1662, 572, 1752, 672], [39, 415, 324, 573], [1402, 537, 1636, 712], [1706, 629, 1920, 1078]])\n list([[1022, 648, 1300, 901], [1756, 591, 1906, 693], [1661, 573, 1751, 672], [38, 413, 328, 576], [1398, 537, 1635, 714], [1705, 629, 1920, 1077]])\n list([[1002, 649, 1285, 906], [1753, 593, 1908, 693], [1660, 574, 1749, 676], [38, 413, 329, 575], [1390, 535, 1628, 717], [1706, 629, 1920, 1078]])\n list([[963, 644, 1279, 911], [1750, 595, 1910, 693], [1657, 572, 1750, 681], [1380, 532, 1628, 719], [38, 417, 329, 574], [1705, 630, 1919, 1077]])\n list([[939, 650, 1244, 915], [1752, 611, 1907, 704], [1658, 571, 1750, 684], [1368, 530, 1628, 725], [37, 419, 328, 576], [1706, 630, 1919, 1077]])\n list([[913, 645, 1221, 921], [1752, 611, 1906, 704], [1656, 571, 1750, 686], [1362, 532, 1626, 726], [38, 418, 329, 576], [1706, 630, 1920, 1077]])\n list([[875, 643, 1220, 924], [1657, 573, 1750, 687], [1353, 530, 1623, 729], [40, 417, 329, 579], [1709, 631, 1920, 1076]])\n list([[849, 645, 1185, 932], [1266, 531, 1410, 646], [1657, 573, 1750, 688], [41, 418, 330, 583], [1331, 529, 1613, 727], [1710, 629, 1920, 1077]])\n list([[804, 634, 1162, 937], [1658, 571, 1748, 688], [1268, 534, 1408, 642], [42, 418, 332, 583], [1329, 525, 1613, 730], [1712, 629, 1919, 1077]])\n list([[1095, 576, 1205, 671], [770, 645, 1121, 941], [1658, 572, 1748, 688], [1280, 530, 1408, 638], [44, 418, 332, 583], [1321, 526, 1617, 732], [1711, 627, 1919, 1078]])\n list([[1106, 585, 1214, 672], [722, 635, 1112, 938], [1649, 573, 1741, 688], [44, 418, 332, 583], [1284, 533, 1404, 638], [1314, 529, 1616, 736], [1711, 627, 1919, 1078]])\n list([[1131, 582, 1221, 668], [690, 643, 1098, 942], [1649, 570, 1742, 689], [1281, 530, 1407, 634], [44, 418, 332, 584], [1312, 530, 1610, 740], [1709, 627, 1919, 1078]])\n list([[1144, 585, 1251, 669], [652, 630, 1059, 964], [1648, 571, 1742, 689], [44, 418, 331, 584], [1312, 534, 1601, 740], [1710, 625, 1919, 1079]])\n list([[1167, 580, 1259, 667], [615, 618, 1039, 969], [1647, 570, 1742, 688], [44, 418, 332, 584], [1301, 529, 1600, 742], [1711, 625, 1919, 1079]])\n list([[1185, 579, 1269, 669], [566, 610, 1011, 977], [1749, 593, 1905, 694], [1646, 569, 1742, 688], [45, 418, 332, 585], [1290, 528, 1598, 743], [1712, 626, 1919, 1079]])\n list([[520, 618, 982, 980], [1749, 593, 1905, 693], [1646, 571, 1740, 688], [45, 419, 332, 584], [1279, 524, 1589, 747], [1710, 627, 1920, 1078]])\n list([[489, 608, 957, 994], [1749, 593, 1905, 694], [1644, 571, 1738, 687], [44, 419, 333, 584], [1268, 524, 1586, 750], [1711, 626, 1920, 1078]])\n list([[443, 614, 895, 991], [1751, 593, 1905, 694], [1644, 571, 1737, 688], [1255, 520, 1584, 752], [43, 419, 332, 584], [1711, 628, 1920, 1078]])\n list([[390, 618, 864, 979], [1752, 609, 1905, 703], [1640, 570, 1735, 688], [1245, 517, 1591, 755], [41, 418, 332, 583], [1710, 628, 1920, 1078]])\n list([[340, 621, 815, 981], [1748, 596, 1907, 692], [1638, 569, 1731, 688], [1235, 513, 1594, 759], [42, 416, 329, 582], [1708, 628, 1920, 1078]])\n list([[305, 638, 794, 980], [1746, 597, 1909, 692], [1636, 567, 1728, 688], [1214, 517, 1565, 754], [36, 418, 330, 576], [1707, 629, 1920, 1077]])\n list([[238, 634, 756, 969], [1744, 598, 1910, 690], [1633, 565, 1727, 690], [1205, 516, 1567, 756], [34, 417, 331, 574], [1704, 628, 1920, 1077]])\n list([[204, 611, 707, 979], [1740, 597, 1911, 691], [1633, 562, 1726, 691], [1189, 512, 1559, 762], [33, 415, 329, 573], [1704, 629, 1920, 1077]])\n list([[156, 626, 667, 972], [1174, 503, 1548, 766], [1740, 597, 1911, 691], [1631, 562, 1725, 693], [34, 414, 324, 571], [1701, 628, 1919, 1077]])\n list([[95, 641, 618, 967], [1163, 506, 1543, 766], [1627, 562, 1723, 693], [1741, 597, 1910, 691], [35, 414, 326, 572], [1697, 627, 1919, 1078]])\n list([[59, 631, 560, 968], [1626, 562, 1721, 696], [1741, 598, 1911, 690], [35, 416, 315, 576], [1695, 628, 1919, 1077]])\n list([[25, 624, 516, 983], [1624, 562, 1720, 698], [1114, 497, 1566, 769], [1741, 598, 1910, 691], [30, 410, 293, 577], [1695, 630, 1918, 1077]])\n list([[7, 642, 463, 962], [1741, 610, 1902, 702], [1621, 563, 1719, 698], [40, 413, 322, 577], [1104, 502, 1521, 774], [1693, 631, 1918, 1076]])\n list([[0, 628, 419, 960], [1508, 583, 1575, 684], [1737, 597, 1909, 690], [1619, 563, 1718, 698], [40, 413, 332, 580], [1693, 630, 1919, 1076]])\n list([[3, 620, 369, 967], [1620, 563, 1717, 699], [1736, 597, 1910, 690], [52, 406, 323, 578], [1694, 631, 1919, 1077]])\n list([[7, 671, 312, 971], [1620, 562, 1716, 701], [1735, 597, 1909, 690], [65, 405, 320, 575], [1697, 631, 1919, 1077]])\n list([[1046, 467, 1494, 802], [0, 672, 275, 959], [1735, 597, 1910, 689], [91, 402, 322, 574], [1696, 631, 1920, 1078]])\n list([[9, 662, 211, 970], [1619, 558, 1714, 700], [106, 412, 320, 568], [1735, 595, 1910, 690], [1698, 629, 1919, 1078]])\n list([[1494, 575, 1558, 681], [0, 658, 175, 963], [145, 414, 317, 569], [1736, 596, 1910, 688], [1699, 627, 1918, 1079]])\n list([[0, 667, 117, 966], [953, 471, 1480, 804], [168, 419, 318, 569], [1735, 597, 1911, 687], [1700, 627, 1919, 1079]])\n list([[0, 340, 282, 638], [1487, 569, 1554, 681], [0, 659, 90, 968], [1609, 561, 1705, 698], [1735, 595, 1909, 687], [934, 475, 1466, 796], [1694, 623, 1916, 1080]])\n list([[0, 338, 291, 644], [1594, 559, 1709, 691], [1737, 593, 1909, 687], [918, 463, 1462, 801], [1693, 621, 1916, 1080]])\n list([[0, 350, 329, 650], [1604, 557, 1704, 701], [1734, 594, 1909, 689], [910, 461, 1471, 809], [1691, 620, 1917, 1080]])\n list([[0, 344, 340, 645], [1476, 572, 1539, 686], [1734, 592, 1910, 689], [862, 469, 1438, 812], [1691, 621, 1917, 1080]])\n list([[3, 351, 367, 646], [1469, 572, 1537, 687], [1589, 559, 1705, 698], [843, 467, 1427, 812], [1734, 592, 1911, 689], [1693, 624, 1918, 1080]])\n list([[1464, 575, 1534, 689], [1589, 560, 1706, 700], [820, 471, 1417, 813], [1735, 594, 1911, 690], [1694, 626, 1919, 1079]])]\n"
     ]
    }
   ],
   "source": [
    "# sample direction array\n",
    "\n",
    "temp_dir_array = np.load(path_direction_train_arrays+'/directions1.npy', allow_pickle=True)\n",
    "print(temp_dir_array)\n",
    "\n",
    "temp_array = np.load(path_train_arrays+'/array1.npy', allow_pickle=True)\n",
    "print(temp_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_region(x,y):\n",
    "\n",
    "    '''\n",
    "    Returns the region in which the particular point lies\n",
    "\n",
    "    Parameters:\n",
    "    x(int) : x coordinate of the point\n",
    "    y(int) : y coordinate of the point\n",
    "\n",
    "    Returns:\n",
    "    int : region no (1/2/3/4/5/6)\n",
    "    '''\n",
    "\n",
    "\n",
    "    video_height = 1080\n",
    "    video_width = 1920\n",
    "\n",
    "    if(x<640 and y>=540):\n",
    "        return 1 #Bottom left\n",
    "    if(x<=1280 and y>=540):\n",
    "        return 2 #Bottom center\n",
    "    if(x>1280 and y>=540):\n",
    "        return 3 #Bottom right\n",
    "    if(x>1280 and y<540):\n",
    "        return 4 #Top right\n",
    "    if(x<=1280 and y<540):\n",
    "        return 5 #Top center\n",
    "    if(x<640 and y<540):\n",
    "        return 6 #Top left\n",
    "\n",
    "def extract_features_from_frame(bounding_boxes, directions_for_boxes, frame_no):\n",
    "        \n",
    "    '''\n",
    "    Extract features from a particular frame\n",
    "\n",
    "    Parameters:\n",
    "    bounding_boxes(array) : detection array of the video\n",
    "    frame_no(int) : frame no for which features are to be extracted\n",
    "\n",
    "    Returns:\n",
    "    list : containing 18 features of the frame\n",
    "    '''    \n",
    "\n",
    "    no_of_boxes = len(bounding_boxes[frame_no])\n",
    "    boxes_frame = np.array(bounding_boxes[frame_no])\n",
    "    direction_frame = np.array(directions_for_boxes[frame_no])\n",
    "\n",
    "    if len(direction_frame) != no_of_boxes:\n",
    "        raise Exception('mismatch in number of boxes '+ str(len(direction_frame))+' '+str(no_of_boxes))\n",
    "\n",
    "    indices_required_boxes = np.where(direction_frame>=0)[0]\n",
    "    no_of_boxes_required = len(indices_required_boxes)\n",
    "\n",
    "    boxes_required = boxes_frame[indices_required_boxes]\n",
    "\n",
    "    #feature - number of vehicles in each region\n",
    "    r1 = r2 = r3 = r4 = r5 = r6 = 0\n",
    "    \n",
    "    #feature - total area of vehicles in each region\n",
    "    r1_area = r2_area = r3_area = r4_area = r5_area = r6_area = 0\n",
    "\n",
    "    # for distance calculation for every region\n",
    "    bottom_center_point_x = 1920/2    # width/2\n",
    "    bottom_center_point_y = 1080      # height\n",
    "    r1_min_distance = r2_min_distance = r3_min_distance = r4_min_distance = r5_min_distance = r6_min_distance = 0\n",
    "\n",
    "    for j in range(len(boxes_required)):\n",
    "\n",
    "        # x coordinate of center of bounding box cx\n",
    "        cx = (boxes_required[j][0] + boxes_required[j][2])/2\n",
    "\n",
    "        # y coordinate of center of bounding box cy\n",
    "        cy = (boxes_required[j][1] + boxes_required[j][3])/2\n",
    "\n",
    "        # area of bounding box\n",
    "        bounding_box_area = ((boxes_required[j][3]-boxes_required[j][1])*\n",
    "                        (boxes_required[j][2]-boxes_required[j][0]))\n",
    "\n",
    "        # distance calculation for every bounding box\n",
    "        distance = sqrt((cx - bottom_center_point_x)**2 + (cy - bottom_center_point_y)**2)\n",
    "\n",
    "        if(find_region(cx,cy)==1):\n",
    "            r1 = r1 + 1\n",
    "            r1_area = r1_area + bounding_box_area\n",
    "            if(r1_min_distance==0 or distance < r1_min_distance):\n",
    "                r1_min_distance = distance\n",
    "        elif(find_region(cx,cy)==2):\n",
    "            r2 = r2 + 1\n",
    "            r2_area = r2_area + bounding_box_area\n",
    "            if(r2_min_distance==0 or distance < r2_min_distance):\n",
    "                r2_min_distance = distance\n",
    "        elif(find_region(cx,cy)==3):\n",
    "            r3 = r3 + 1\n",
    "            r3_area = r3_area + bounding_box_area\n",
    "            if(r3_min_distance==0 or distance < r3_min_distance):\n",
    "                r3_min_distance = distance\n",
    "        elif(find_region(cx,cy)==4):\n",
    "            r4 = r4 + 1\n",
    "            r4_area = r4_area + bounding_box_area\n",
    "            if(r4_min_distance==0 or distance < r4_min_distance):\n",
    "                r4_min_distance = distance\n",
    "        elif(find_region(cx,cy)==5):\n",
    "            r5 = r5 + 1\n",
    "            r5_area = r5_area + bounding_box_area\n",
    "            if(r5_min_distance==0 or distance < r5_min_distance):\n",
    "                r5_min_distance = distance\n",
    "        elif(find_region(cx,cy)==6):\n",
    "            r6 = r6 + 1\n",
    "            r6_area = r6_area + bounding_box_area\n",
    "            if(r6_min_distance==0 or distance < r6_min_distance):\n",
    "                r6_min_distance = distance\n",
    "                \n",
    "    features_frame = [r1,r1_area,r1_min_distance,r2,r2_area,r2_min_distance,r3,r3_area,r3_min_distance,r4,r4_area,r4_min_distance,r5,r5_area,r5_min_distance,r6,r6_area,r6_min_distance]\n",
    "        \n",
    "    return features_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_from_video(findex, no_frames, labels_csv):\n",
    "    \n",
    "    '''\n",
    "    Get labels for a particular video \n",
    "\n",
    "    Parameters:\n",
    "    findex(int) : video number in labels_csv for which labels are to be generated(starting from 0)\n",
    "    no_frames(int) : no of frames in the given video\n",
    "    labels_csv : the manually marked labels\n",
    "\n",
    "    Returns:\n",
    "    list : list with len = no of frames and the value at each index represents safe/unsafe at that frame_no (frame_no starting at 0)\n",
    "    int : -1 if there is no safe duration in video, 1 otherwise\n",
    "    '''\n",
    "\n",
    "    labels = [0]*no_frames\n",
    "    #print(findex,no_frames)\n",
    "    if(np.isnan(labels_csv[findex][0])):\n",
    "        return labels,-1 #there is no safe duration in the given video so all labels marked 0\n",
    "    else:\n",
    "        j = 0\n",
    "        while(j<len(labels_csv[findex]) and not(np.isnan(labels_csv[findex][j]))):\n",
    "            #mapping safe_start and safe_end in seconds to frame no\n",
    "            #not that frame no starts with 0\n",
    "            safe_start = max(int(labels_csv[findex][j]*30)-1,0) \n",
    "            safe_end = min(int(labels_csv[findex][j+1]*30)-1, no_frames-1)\n",
    "            labels[safe_start:safe_end+1] = [1]*(safe_end-safe_start+1) #marking the value b/w safe_start and safe_end with 1\n",
    "            j = j+2\n",
    "    if len(labels) > no_frames: #len of labels cannot be greater than no_frames in video\n",
    "        raise Exception('Check the labels assigned in CSV file!')\n",
    "    return labels,1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternate generate_datafrmae function with frames selected from unsafe videos\n",
    "def generate_dataframe(arrays_folder, direction_arrays_folder, findex, labels_csv):\n",
    "\n",
    "    '''\n",
    "    Generate dataframes for model training\n",
    "\n",
    "    Parameters:\n",
    "    arrays_folder(path) : folder containing detection arrays\n",
    "    videos_folder(path) : folder containing videos\n",
    "    findex(int) : array number to start with from the given folder (starting from 0)\n",
    "    labels_csv : the manually marked labels\n",
    "\n",
    "    Returns:\n",
    "    features_dataframe : dataframe containg 18 features per frame\n",
    "    labels_dataframe : dataframe containing 1 label per frame\n",
    "    '''\n",
    "    \n",
    "    #getting all paths of all arrays in a list in proper order \n",
    "    arrays = glob.glob(arrays_folder+'/array*.npy')\n",
    "    arrays = natsort.natsorted(arrays)\n",
    "\n",
    "    # getting all paths of all direction arrays in a list in proper order\n",
    "    direction_arrays = glob.glob(direction_arrays_folder+'/directions*.npy')\n",
    "    direction_arrays = natsort.natsorted(direction_arrays)\n",
    "\n",
    "    cols_f = ['region1','region1_area','region1_min_distance','region2','region2_area','region2_min_distance','region3','region3_area','region3_min_distance','region4','region4_area','region4_min_distance','region5','region5_area','region5_min_distance','region6','region6_area','region6_min_distance'] #18 features per frame\n",
    "    cols_l = ['safe/unsafe'] #1 label per frame\n",
    "    features_dataframe = pd.DataFrame()\n",
    "    labels_dataframe = pd.DataFrame()\n",
    "\n",
    "    for fname,directions_path in zip(arrays, direction_arrays):\n",
    "        \n",
    "        print(\"processing \",fname,\":\")\n",
    "        bounding_boxes = np.load(fname, allow_pickle=True) #loading the numpy array containing all detected vehicles\n",
    "        directions_for_boxes = np.load(directions_path, allow_pickle=True) # loading the arrays containing detected directions for each bounding box\n",
    "        no_frames = bounding_boxes.shape[0]\n",
    "        print(\"no of frames: \", no_frames)\n",
    "        labels, flag = get_labels_from_video(findex, no_frames, labels_csv)\n",
    "        print('flag', flag)\n",
    "\n",
    "        labels_0 = [i for i, value in enumerate(labels) if value == 0 and i>6]\n",
    "        # shuffling unsafe frames\n",
    "        random.shuffle(labels_0)\n",
    "        # selecting 50 frames from unsafe videos instead of rejecting the whole video\n",
    "        if(len(labels_0) >= 50): \n",
    "            labels_0 = labels_0[:50]\n",
    "\n",
    "        if(flag == -1):\n",
    "            print('no safe time')\n",
    "            labels_1 = []\n",
    "        else:\n",
    "            labels_1 = [i for i, value in enumerate(labels) if value == 1 and i>6]\n",
    "            # shuffling safe frames\n",
    "            random.shuffle(labels_1)\n",
    "            ## selecting no of safe frames = no of unsafe frames from each video ##\n",
    "            # label 0 frames will be more than label 1 frame, \n",
    "            # so we will try to select same number of safe and unsafe frames\n",
    "            if(len(labels_0) >= len(labels_1)):\n",
    "                labels_0 = labels_0[:len(labels_1)]\n",
    "\n",
    "        features = []\n",
    "            \n",
    "        # selecting number of safe and unsafe frames for model training\n",
    "        ####### to be changed after thinking\n",
    "        # selecting only 50 frames of each label from a video\n",
    "        # random.shuffle(labels_0)\n",
    "        # random.shuffle(labels_1)\n",
    "        # if(len(labels_0) >= 50): \n",
    "        #     labels_0 = labels_0[:50]\n",
    "        # if(len(labels_1) >= 50): \n",
    "        #     labels_1 = labels_1[:50]  \n",
    "        ####### \n",
    " \n",
    "\n",
    "        for frame_no in labels_0:\n",
    "            features_frame = extract_features_from_frame(bounding_boxes, directions_for_boxes, frame_no)\n",
    "            features.append(features_frame)\n",
    "        for frame_no in labels_1:\n",
    "            features_frame = extract_features_from_frame(bounding_boxes, directions_for_boxes, frame_no)\n",
    "            features.append(features_frame)\n",
    "        \n",
    "        #generating and returning features and labels dataframes\n",
    "        no_frames_in_features = len(features)\n",
    "        print(\"no_frames_in_features\",no_frames_in_features)\n",
    "        labels = [0]*len(labels_0) + [1]*len(labels_1)\n",
    "        print(\"no_of_frames_in_labels\", len(labels))\n",
    "        findex = findex + 1\n",
    "        df1 = pd.DataFrame(features, columns=cols_f)\n",
    "        features_dataframe = features_dataframe.append(df1,ignore_index=True)\n",
    "        print(\"df1.size\",df1.shape)\n",
    "        df2 = pd.DataFrame(labels, columns=cols_l)\n",
    "        labels_dataframe = labels_dataframe.append(df2,ignore_index=True)\n",
    "        print(\"df2.size\",df2.shape)\n",
    "        \n",
    "    return features_dataframe, labels_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60, 4) (16, 6)\n"
     ]
    }
   ],
   "source": [
    "from numpy import genfromtxt\n",
    "\n",
    "labels_train = genfromtxt(path_train_labels, delimiter =',')\n",
    "labels_test = genfromtxt(path_test_labels, delimiter =',')\n",
    "print(labels_train.shape, labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array1.npy :\n",
      "no of frames:  210\n",
      "flag -1\n",
      "no safe time\n",
      "no_frames_in_features 50\n",
      "no_of_frames_in_labels 50\n",
      "df1.size (50, 18)\n",
      "df2.size (50, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array2.npy :\n",
      "no of frames:  150\n",
      "flag 1\n",
      "no_frames_in_features 143\n",
      "no_of_frames_in_labels 143\n",
      "df1.size (143, 18)\n",
      "df2.size (143, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array3.npy :\n",
      "no of frames:  180\n",
      "flag 1\n",
      "no_frames_in_features 111\n",
      "no_of_frames_in_labels 111\n",
      "df1.size (111, 18)\n",
      "df2.size (111, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array4.npy :\n",
      "no of frames:  150\n",
      "flag -1\n",
      "no safe time\n",
      "no_frames_in_features 50\n",
      "no_of_frames_in_labels 50\n",
      "df1.size (50, 18)\n",
      "df2.size (50, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array5.npy :\n",
      "no of frames:  240\n",
      "flag -1\n",
      "no safe time\n",
      "no_frames_in_features 50\n",
      "no_of_frames_in_labels 50\n",
      "df1.size (50, 18)\n",
      "df2.size (50, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array6.npy :\n",
      "no of frames:  210\n",
      "flag -1\n",
      "no safe time\n",
      "no_frames_in_features 50\n",
      "no_of_frames_in_labels 50\n",
      "df1.size (50, 18)\n",
      "df2.size (50, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array7.npy :\n",
      "no of frames:  210\n",
      "flag -1\n",
      "no safe time\n",
      "no_frames_in_features 50\n",
      "no_of_frames_in_labels 50\n",
      "df1.size (50, 18)\n",
      "df2.size (50, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array8.npy :\n",
      "no of frames:  150\n",
      "flag 1\n",
      "no_frames_in_features 141\n",
      "no_of_frames_in_labels 141\n",
      "df1.size (141, 18)\n",
      "df2.size (141, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array9.npy :\n",
      "no of frames:  150\n",
      "flag 1\n",
      "no_frames_in_features 141\n",
      "no_of_frames_in_labels 141\n",
      "df1.size (141, 18)\n",
      "df2.size (141, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array10.npy :\n",
      "no of frames:  150\n",
      "flag 1\n",
      "no_frames_in_features 133\n",
      "no_of_frames_in_labels 133\n",
      "df1.size (133, 18)\n",
      "df2.size (133, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array11.npy :\n",
      "no of frames:  210\n",
      "flag -1\n",
      "no safe time\n",
      "no_frames_in_features 50\n",
      "no_of_frames_in_labels 50\n",
      "df1.size (50, 18)\n",
      "df2.size (50, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array12.npy :\n",
      "no of frames:  180\n",
      "flag 1\n",
      "no_frames_in_features 62\n",
      "no_of_frames_in_labels 62\n",
      "df1.size (62, 18)\n",
      "df2.size (62, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array13.npy :\n",
      "no of frames:  240\n",
      "flag -1\n",
      "no safe time\n",
      "no_frames_in_features 50\n",
      "no_of_frames_in_labels 50\n",
      "df1.size (50, 18)\n",
      "df2.size (50, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array14.npy :\n",
      "no of frames:  180\n",
      "flag 1\n",
      "no_frames_in_features 111\n",
      "no_of_frames_in_labels 111\n",
      "df1.size (111, 18)\n",
      "df2.size (111, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array15.npy :\n",
      "no of frames:  180\n",
      "flag -1\n",
      "no safe time\n",
      "no_frames_in_features 50\n",
      "no_of_frames_in_labels 50\n",
      "df1.size (50, 18)\n",
      "df2.size (50, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array16.npy :\n",
      "no of frames:  210\n",
      "flag 1\n",
      "no_frames_in_features 142\n",
      "no_of_frames_in_labels 142\n",
      "df1.size (142, 18)\n",
      "df2.size (142, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array17.npy :\n",
      "no of frames:  330\n",
      "flag 1\n",
      "no_frames_in_features 141\n",
      "no_of_frames_in_labels 141\n",
      "df1.size (141, 18)\n",
      "df2.size (141, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array18.npy :\n",
      "no of frames:  210\n",
      "flag -1\n",
      "no safe time\n",
      "no_frames_in_features 50\n",
      "no_of_frames_in_labels 50\n",
      "df1.size (50, 18)\n",
      "df2.size (50, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array19.npy :\n",
      "no of frames:  180\n",
      "flag -1\n",
      "no safe time\n",
      "no_frames_in_features 50\n",
      "no_of_frames_in_labels 50\n",
      "df1.size (50, 18)\n",
      "df2.size (50, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array20.npy :\n",
      "no of frames:  210\n",
      "flag 1\n",
      "no_frames_in_features 172\n",
      "no_of_frames_in_labels 172\n",
      "df1.size (172, 18)\n",
      "df2.size (172, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array21.npy :\n",
      "no of frames:  180\n",
      "flag 1\n",
      "no_frames_in_features 111\n",
      "no_of_frames_in_labels 111\n",
      "df1.size (111, 18)\n",
      "df2.size (111, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array22.npy :\n",
      "no of frames:  150\n",
      "flag 1\n",
      "no_frames_in_features 141\n",
      "no_of_frames_in_labels 141\n",
      "df1.size (141, 18)\n",
      "df2.size (141, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array23.npy :\n",
      "no of frames:  180\n",
      "flag -1\n",
      "no safe time\n",
      "no_frames_in_features 50\n",
      "no_of_frames_in_labels 50\n",
      "df1.size (50, 18)\n",
      "df2.size (50, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array24.npy :\n",
      "no of frames:  240\n",
      "flag -1\n",
      "no safe time\n",
      "no_frames_in_features 50\n",
      "no_of_frames_in_labels 50\n",
      "df1.size (50, 18)\n",
      "df2.size (50, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array25.npy :\n",
      "no of frames:  180\n",
      "flag -1\n",
      "no safe time\n",
      "no_frames_in_features 50\n",
      "no_of_frames_in_labels 50\n",
      "df1.size (50, 18)\n",
      "df2.size (50, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array26.npy :\n",
      "no of frames:  210\n",
      "flag -1\n",
      "no safe time\n",
      "no_frames_in_features 50\n",
      "no_of_frames_in_labels 50\n",
      "df1.size (50, 18)\n",
      "df2.size (50, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array27.npy :\n",
      "no of frames:  180\n",
      "flag 1\n",
      "no_frames_in_features 142\n",
      "no_of_frames_in_labels 142\n",
      "df1.size (142, 18)\n",
      "df2.size (142, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array28.npy :\n",
      "no of frames:  180\n",
      "flag 1\n",
      "no_frames_in_features 172\n",
      "no_of_frames_in_labels 172\n",
      "df1.size (172, 18)\n",
      "df2.size (172, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array29.npy :\n",
      "no of frames:  180\n",
      "flag -1\n",
      "no safe time\n",
      "no_frames_in_features 50\n",
      "no_of_frames_in_labels 50\n",
      "df1.size (50, 18)\n",
      "df2.size (50, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array30.npy :\n",
      "no of frames:  180\n",
      "flag 1\n",
      "no_frames_in_features 171\n",
      "no_of_frames_in_labels 171\n",
      "df1.size (171, 18)\n",
      "df2.size (171, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array31.npy :\n",
      "no of frames:  210\n",
      "flag 1\n",
      "no_frames_in_features 141\n",
      "no_of_frames_in_labels 141\n",
      "df1.size (141, 18)\n",
      "df2.size (141, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array32.npy :\n",
      "no of frames:  150\n",
      "flag 1\n",
      "no_frames_in_features 142\n",
      "no_of_frames_in_labels 142\n",
      "df1.size (142, 18)\n",
      "df2.size (142, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array33.npy :\n",
      "no of frames:  180\n",
      "flag 1\n",
      "no_frames_in_features 141\n",
      "no_of_frames_in_labels 141\n",
      "df1.size (141, 18)\n",
      "df2.size (141, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array34.npy :\n",
      "no of frames:  150\n",
      "flag -1\n",
      "no safe time\n",
      "no_frames_in_features 50\n",
      "no_of_frames_in_labels 50\n",
      "df1.size (50, 18)\n",
      "df2.size (50, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array35.npy :\n",
      "no of frames:  210\n",
      "flag 1\n",
      "no_frames_in_features 111\n",
      "no_of_frames_in_labels 111\n",
      "df1.size (111, 18)\n",
      "df2.size (111, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array36.npy :\n",
      "no of frames:  180\n",
      "flag -1\n",
      "no safe time\n",
      "no_frames_in_features 50\n",
      "no_of_frames_in_labels 50\n",
      "df1.size (50, 18)\n",
      "df2.size (50, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array37.npy :\n",
      "no of frames:  180\n",
      "flag -1\n",
      "no safe time\n",
      "no_frames_in_features 50\n",
      "no_of_frames_in_labels 50\n",
      "df1.size (50, 18)\n",
      "df2.size (50, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array38.npy :\n",
      "no of frames:  180\n",
      "flag 1\n",
      "no_frames_in_features 111\n",
      "no_of_frames_in_labels 111\n",
      "df1.size (111, 18)\n",
      "df2.size (111, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array39.npy :\n",
      "no of frames:  180\n",
      "flag 1\n",
      "no_frames_in_features 172\n",
      "no_of_frames_in_labels 172\n",
      "df1.size (172, 18)\n",
      "df2.size (172, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array40.npy :\n",
      "no of frames:  210\n",
      "flag -1\n",
      "no safe time\n",
      "no_frames_in_features 50\n",
      "no_of_frames_in_labels 50\n",
      "df1.size (50, 18)\n",
      "df2.size (50, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array41.npy :\n",
      "no of frames:  180\n",
      "flag -1\n",
      "no safe time\n",
      "no_frames_in_features 50\n",
      "no_of_frames_in_labels 50\n",
      "df1.size (50, 18)\n",
      "df2.size (50, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array42.npy :\n",
      "no of frames:  180\n",
      "flag 1\n",
      "no_frames_in_features 111\n",
      "no_of_frames_in_labels 111\n",
      "df1.size (111, 18)\n",
      "df2.size (111, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array43.npy :\n",
      "no of frames:  240\n",
      "flag 1\n",
      "no_frames_in_features 172\n",
      "no_of_frames_in_labels 172\n",
      "df1.size (172, 18)\n",
      "df2.size (172, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array44.npy :\n",
      "no of frames:  180\n",
      "flag -1\n",
      "no safe time\n",
      "no_frames_in_features 50\n",
      "no_of_frames_in_labels 50\n",
      "df1.size (50, 18)\n",
      "df2.size (50, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array45.npy :\n",
      "no of frames:  180\n",
      "flag 1\n",
      "no_frames_in_features 111\n",
      "no_of_frames_in_labels 111\n",
      "df1.size (111, 18)\n",
      "df2.size (111, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array46.npy :\n",
      "no of frames:  180\n",
      "flag -1\n",
      "no safe time\n",
      "no_frames_in_features 50\n",
      "no_of_frames_in_labels 50\n",
      "df1.size (50, 18)\n",
      "df2.size (50, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array47.npy :\n",
      "no of frames:  180\n",
      "flag 1\n",
      "no_frames_in_features 141\n",
      "no_of_frames_in_labels 141\n",
      "df1.size (141, 18)\n",
      "df2.size (141, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array48.npy :\n",
      "no of frames:  180\n",
      "flag 1\n",
      "no_frames_in_features 171\n",
      "no_of_frames_in_labels 171\n",
      "df1.size (171, 18)\n",
      "df2.size (171, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array49.npy :\n",
      "no of frames:  180\n",
      "flag 1\n",
      "no_frames_in_features 111\n",
      "no_of_frames_in_labels 111\n",
      "df1.size (111, 18)\n",
      "df2.size (111, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array50.npy :\n",
      "no of frames:  180\n",
      "flag 1\n",
      "no_frames_in_features 111\n",
      "no_of_frames_in_labels 111\n",
      "df1.size (111, 18)\n",
      "df2.size (111, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array51.npy :\n",
      "no of frames:  180\n",
      "flag 1\n",
      "no_frames_in_features 141\n",
      "no_of_frames_in_labels 141\n",
      "df1.size (141, 18)\n",
      "df2.size (141, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array52.npy :\n",
      "no of frames:  180\n",
      "flag 1\n",
      "no_frames_in_features 163\n",
      "no_of_frames_in_labels 163\n",
      "df1.size (163, 18)\n",
      "df2.size (163, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array53.npy :\n",
      "no of frames:  180\n",
      "flag 1\n",
      "no_frames_in_features 133\n",
      "no_of_frames_in_labels 133\n",
      "df1.size (133, 18)\n",
      "df2.size (133, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array54.npy :\n",
      "no of frames:  180\n",
      "flag 1\n",
      "no_frames_in_features 141\n",
      "no_of_frames_in_labels 141\n",
      "df1.size (141, 18)\n",
      "df2.size (141, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array55.npy :\n",
      "no of frames:  180\n",
      "flag 1\n",
      "no_frames_in_features 141\n",
      "no_of_frames_in_labels 141\n",
      "df1.size (141, 18)\n",
      "df2.size (141, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array56.npy :\n",
      "no of frames:  180\n",
      "flag -1\n",
      "no safe time\n",
      "no_frames_in_features 50\n",
      "no_of_frames_in_labels 50\n",
      "df1.size (50, 18)\n",
      "df2.size (50, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array57.npy :\n",
      "no of frames:  180\n",
      "flag -1\n",
      "no safe time\n",
      "no_frames_in_features 50\n",
      "no_of_frames_in_labels 50\n",
      "df1.size (50, 18)\n",
      "df2.size (50, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array58.npy :\n",
      "no of frames:  180\n",
      "flag 1\n",
      "no_frames_in_features 173\n",
      "no_of_frames_in_labels 173\n",
      "df1.size (173, 18)\n",
      "df2.size (173, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array59.npy :\n",
      "no of frames:  180\n",
      "flag 1\n",
      "no_frames_in_features 133\n",
      "no_of_frames_in_labels 133\n",
      "df1.size (133, 18)\n",
      "df2.size (133, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_train/array60.npy :\n",
      "no of frames:  180\n",
      "flag 1\n",
      "no_frames_in_features 172\n",
      "no_of_frames_in_labels 172\n",
      "df1.size (172, 18)\n",
      "df2.size (172, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_test/array61.npy :\n",
      "no of frames:  180\n",
      "flag 1\n",
      "no_frames_in_features 171\n",
      "no_of_frames_in_labels 171\n",
      "df1.size (171, 18)\n",
      "df2.size (171, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_test/array62.npy :\n",
      "no of frames:  210\n",
      "flag 1\n",
      "no_frames_in_features 165\n",
      "no_of_frames_in_labels 165\n",
      "df1.size (165, 18)\n",
      "df2.size (165, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_test/array63.npy :\n",
      "no of frames:  180\n",
      "flag 1\n",
      "no_frames_in_features 173\n",
      "no_of_frames_in_labels 173\n",
      "df1.size (173, 18)\n",
      "df2.size (173, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_test/array64.npy :\n",
      "no of frames:  180\n",
      "flag 1\n",
      "no_frames_in_features 142\n",
      "no_of_frames_in_labels 142\n",
      "df1.size (142, 18)\n",
      "df2.size (142, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_test/array65.npy :\n",
      "no of frames:  180\n",
      "flag 1\n",
      "no_frames_in_features 172\n",
      "no_of_frames_in_labels 172\n",
      "df1.size (172, 18)\n",
      "df2.size (172, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_test/array66.npy :\n",
      "no of frames:  180\n",
      "flag 1\n",
      "no_frames_in_features 172\n",
      "no_of_frames_in_labels 172\n",
      "df1.size (172, 18)\n",
      "df2.size (172, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_test/array67.npy :\n",
      "no of frames:  180\n",
      "flag 1\n",
      "no_frames_in_features 141\n",
      "no_of_frames_in_labels 141\n",
      "df1.size (141, 18)\n",
      "df2.size (141, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_test/array68.npy :\n",
      "no of frames:  180\n",
      "flag 1\n",
      "no_frames_in_features 142\n",
      "no_of_frames_in_labels 142\n",
      "df1.size (142, 18)\n",
      "df2.size (142, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_test/array69.npy :\n",
      "no of frames:  180\n",
      "flag 1\n",
      "no_frames_in_features 111\n",
      "no_of_frames_in_labels 111\n",
      "df1.size (111, 18)\n",
      "df2.size (111, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_test/array70.npy :\n",
      "no of frames:  180\n",
      "flag 1\n",
      "no_frames_in_features 111\n",
      "no_of_frames_in_labels 111\n",
      "df1.size (111, 18)\n",
      "df2.size (111, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_test/array71.npy :\n",
      "no of frames:  180\n",
      "flag -1\n",
      "no safe time\n",
      "no_frames_in_features 50\n",
      "no_of_frames_in_labels 50\n",
      "df1.size (50, 18)\n",
      "df2.size (50, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_test/array72.npy :\n",
      "no of frames:  180\n",
      "flag -1\n",
      "no safe time\n",
      "no_frames_in_features 50\n",
      "no_of_frames_in_labels 50\n",
      "df1.size (50, 18)\n",
      "df2.size (50, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_test/array73.npy :\n",
      "no of frames:  180\n",
      "flag -1\n",
      "no safe time\n",
      "no_frames_in_features 50\n",
      "no_of_frames_in_labels 50\n",
      "df1.size (50, 18)\n",
      "df2.size (50, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_test/array74.npy :\n",
      "no of frames:  180\n",
      "flag -1\n",
      "no safe time\n",
      "no_frames_in_features 50\n",
      "no_of_frames_in_labels 50\n",
      "df1.size (50, 18)\n",
      "df2.size (50, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_test/array75.npy :\n",
      "no of frames:  180\n",
      "flag -1\n",
      "no safe time\n",
      "no_frames_in_features 50\n",
      "no_of_frames_in_labels 50\n",
      "df1.size (50, 18)\n",
      "df2.size (50, 1)\n",
      "processing  /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays_test/array76.npy :\n",
      "no of frames:  210\n",
      "flag 1\n",
      "no_frames_in_features 203\n",
      "no_of_frames_in_labels 203\n",
      "df1.size (203, 18)\n",
      "df2.size (203, 1)\n",
      "(6177, 18)\n"
     ]
    }
   ],
   "source": [
    "features_df_train, labels_df_train = generate_dataframe(path_train_arrays, path_direction_train_arrays,0,labels_train)\n",
    "# features_df_train.to_pickle('features_df_train.pkl')\n",
    "# labels_df_train.to_pickle('labels_df_train.pkl')\n",
    "\n",
    "features_df_test, labels_df_test = generate_dataframe(path_test_arrays, path_direction_test_arrays, 0,labels_test)\n",
    "# features_df_test.to_pickle('features_df_test.pkl')\n",
    "# labels_df_test.to_pickle('labels_df_test.pkl')\n",
    "print(features_df_train.shape)"
   ]
  },
  {
   "source": [
    "## Feature scaling\n",
    "Strategies that can be used: \n",
    "### 1. MinMaxScaler\n",
    "### 2. StandardScaler\n",
    "### 3. Unit Vector Scaler"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# StandardScaler\n",
    "# feature_scaler = StandardScaler()\n",
    "\n",
    "# MinMaxScaler\n",
    "feature_scaler = MinMaxScaler()\n",
    "\n",
    "features_train_scaled = pd.DataFrame(feature_scaler.fit_transform(features_df_train))\n",
    "features_train_scaled.columns = ['region1','region1_area','region1_min_distance','region2','region2_area','region2_min_distance','region3','region3_area','region3_min_distance','region4','region4_area','region4_min_distance','region5','region5_area','region5_min_distance','region6','region6_area','region6_min_distance']\n",
    "features_test_scaled = pd.DataFrame(feature_scaler.transform(features_df_test))\n",
    "features_test_scaled.columns = ['region1','region1_area','region1_min_distance','region2','region2_area','region2_min_distance','region3','region3_area','region3_min_distance','region4','region4_area','region4_min_distance','region5','region5_area','region5_min_distance','region6','region6_area','region6_min_distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "for train data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.64      0.71      2925\n",
      "           1       0.72      0.85      0.78      3252\n",
      "\n",
      "    accuracy                           0.75      6177\n",
      "   macro avg       0.76      0.74      0.74      6177\n",
      "weighted avg       0.76      0.75      0.75      6177\n",
      "\n",
      "accuracy score 0.7498785818358427\n",
      "\n",
      "for test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.48      0.53       722\n",
      "           1       0.73      0.81      0.77      1231\n",
      "\n",
      "    accuracy                           0.69      1953\n",
      "   macro avg       0.66      0.65      0.65      1953\n",
      "weighted avg       0.68      0.69      0.68      1953\n",
      "\n",
      "accuracy score 0.6881720430107527\n"
     ]
    }
   ],
   "source": [
    "# scaled dataset\n",
    "\n",
    "model = SVC(random_state=0)\n",
    "model.fit(features_train_scaled, labels_df_train) \n",
    "from sklearn.metrics import accuracy_score\n",
    " \n",
    "# print prediction results \n",
    "print(\"for train data:\")\n",
    "predictions = model.predict(features_train_scaled) \n",
    "print(classification_report(labels_df_train, predictions)) \n",
    "print(\"accuracy score\", accuracy_score(labels_df_train, predictions))\n",
    "\n",
    "print(\"\\nfor test data:\")\n",
    "predictions = model.predict(features_test_scaled) \n",
    "print(classification_report(labels_df_test, predictions)) \n",
    "print(\"accuracy score\",accuracy_score(labels_df_test, predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit ('roadcross': conda)",
   "metadata": {
    "interpreter": {
     "hash": "abb28e98133ceb27376a192856ef61642bcc9b6f5f609cc2f30f38046f9ba9a9"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}