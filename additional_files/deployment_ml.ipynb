{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python373jvsc74a57bd0efbaad368bcd49cf5b8b1d4bc08527738fe3c05d47d6e3ea110540aa6c36949d",
   "display_name": "Python 3.7.3 64-bit ('roadcross': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import glob\n",
    "from imageai.Detection import VideoObjectDetection\n",
    "import natsort\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import glob\n",
    "from imageai.Detection import VideoObjectDetection\n",
    "import natsort\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from imageai.Detection import VideoObjectDetection\n",
    "import os\n",
    "import sys\n",
    "from random import randint\n",
    "from math import ceil, nan, sqrt\n",
    "import natsort\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sys\n",
    "import cv2\n",
    "from random import randint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "car  :  42.50149130821228  :  [1397, 494, 1479, 588]\n--------------------------------\ncar  :  57.264167070388794  :  [1411, 490, 1563, 631]\n--------------------------------\ntruck  :  52.60764956474304  :  [30, 360, 323, 527]\n--------------------------------\ncar  :  55.52141070365906  :  [41, 358, 329, 525]\n--------------------------------\nmotorcycle  :  79.2188286781311  :  [1, 460, 193, 647]\n--------------------------------\nmotorcycle  :  83.647620677948  :  [1056, 529, 1230, 696]\n--------------------------------\nmotorcycle  :  88.93356323242188  :  [387, 547, 795, 839]\n--------------------------------\ntruck  :  62.59300112724304  :  [516, 310, 1058, 608]\n--------------------------------\ncar  :  73.24953079223633  :  [1677, 570, 1900, 1046]\n--------------------------------\n"
     ]
    }
   ],
   "source": [
    "from imageai.Detection import ObjectDetection\n",
    "import os\n",
    "\n",
    "execution_path = os.getcwd()\n",
    "\n",
    "detector = ObjectDetection()\n",
    "detector.setModelTypeAsRetinaNet()\n",
    "detector.setModelPath( os.path.join(execution_path , \"C:/RoadCrossingAssistant/Data/resnet50_coco_best_v2.0.1.h5\"))\n",
    "detector.loadModel()\n",
    "custom_objects = detector.CustomObjects(bicycle=True, motorcycle=True,car=True,truck=True)\n",
    "detections = detector.detectCustomObjectsFromImage(custom_objects = custom_objects,input_image=os.path.join(execution_path , \"C:/RoadCrossingAssistant/Data/Frames/video1/frame20.jpg\"), output_image_path=os.path.join(execution_path , \"image2new.jpg\"), minimum_percentage_probability=40)\n",
    "\n",
    "\n",
    "\n",
    "for eachObject in detections:\n",
    "    print(eachObject[\"name\"] , \" : \", eachObject[\"percentage_probability\"], \" : \", eachObject[\"box_points\"] )\n",
    "    print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1397, 494, 1479, 588], [1411, 490, 1563, 631], [30, 360, 323, 527], [41, 358, 329, 525], [1, 460, 193, 647], [1056, 529, 1230, 696], [387, 547, 795, 839], [516, 310, 1058, 608], [1677, 570, 1900, 1046]]\n"
     ]
    }
   ],
   "source": [
    "bboxes = []\n",
    "            \n",
    "for i in range(len(detections)):\n",
    "    bboxes.append(list(detections[i]['box_points']))\n",
    "                \n",
    "print(bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1396, 488, 1516, 590], [1412, 490, 1562, 625], [1057, 527, 1232, 699], [39, 357, 326, 527], [43, 358, 328, 526], [4, 439, 193, 648], [1625, 550, 1739, 753], [1476, 555, 1734, 759], [530, 309, 1053, 597], [386, 485, 793, 798], [1676, 630, 1902, 1041]]\n"
     ]
    }
   ],
   "source": [
    "x = np.load(\"C:/RoadCrossingAssistant/Data/Arrays_RetinaNet/array1.npy\", allow_pickle=True)\n",
    "print(x[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trackerTypes = ['BOOSTING', 'MIL', 'KCF','TLD', 'MEDIANFLOW', 'GOTURN', 'MOSSE', 'CSRT']\n",
    "\n",
    "def createTrackerByName(trackerType):\n",
    "    \n",
    "  # Create a tracker based on tracker name\n",
    "    if trackerType == trackerTypes[0]:\n",
    "        tracker = cv2.TrackerBoosting_create()\n",
    "  \n",
    "    elif trackerType == trackerTypes[1]: \n",
    "        tracker = cv2.TrackerMIL_create()\n",
    "   \n",
    "    elif trackerType == trackerTypes[2]:\n",
    "        tracker = cv2.TrackerKCF_create()\n",
    "  \n",
    "    elif trackerType == trackerTypes[3]:\n",
    "        tracker = cv2.TrackerTLD_create()\n",
    "   \n",
    "    elif trackerType == trackerTypes[4]:\n",
    "        tracker = cv2.TrackerMedianFlow_create()\n",
    "    \n",
    "    elif trackerType == trackerTypes[5]:\n",
    "        tracker = cv2.TrackerGOTURN_create()\n",
    "            \n",
    "    elif trackerType == trackerTypes[6]:\n",
    "        tracker = cv2.TrackerMOSSE_create()\n",
    "        \n",
    "    elif trackerType == trackerTypes[7]:\n",
    "        tracker = cv2.TrackerCSRT_create()\n",
    "        \n",
    "    else:\n",
    "        tracker = None\n",
    "        print('Incorrect tracker name')\n",
    "        print('Available trackers are:')\n",
    "        for t in trackerTypes:\n",
    "            print(t)\n",
    "     \n",
    "    return tracker\n",
    "\n",
    "\n",
    "def get_direction(videoPath, trackerType, boxes_list, frame_no):\n",
    "\n",
    "    '''\n",
    "    Detects direction of each vehicle in the video and returns and a list \n",
    "    containing these directions\n",
    "\n",
    "    Parameters:\n",
    "    videoPath(string) : path of the video\n",
    "    trackerType(string) : the openCV tracker type to be used  \n",
    "    boxes_list(list) : list containing bounding boxes for all detected vehicles \n",
    "    frame_no : frame no of the video for which you require directions\n",
    "\n",
    "    '''\n",
    "    k = 0 #iterator for frame no\n",
    "    multiTracker_back = cv2.MultiTracker_create()\n",
    "    #multiTracker = cv2.MultiTracker_create()\n",
    "    n = len(boxes_list)\n",
    "    directions = [0]*n\n",
    "    x1 = [0]*n  #x coordinates of vehicles in frame_no\n",
    "    x2 = [0]*n  #x coordinates of vehicles in frame_no - 5\n",
    "\n",
    "    #reading the video\n",
    "    cap = cv2.VideoCapture(videoPath)\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print('Failed to read video')\n",
    "        sys.exit(1)\n",
    "\n",
    "    #the direction detection logic starts here\n",
    "    while cap.isOpened() :\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        \n",
    "        #saving past few frames as we will apply traking in backward direction\n",
    "        #form the frame_no\n",
    "        if( k == frame_no -10 ):\n",
    "            frame_b10 = frame\n",
    "        if ( k == frame_no - 9):\n",
    "            frame_b9 = frame\n",
    "        if ( k == frame_no - 8):\n",
    "            frame_b8 = frame\n",
    "        if ( k == frame_no - 7):\n",
    "            frame_b7 = frame\n",
    "        if ( k == frame_no - 6):\n",
    "            frame_b6 = frame\n",
    "        if ( k == frame_no - 5):\n",
    "            frame_b5 = frame\n",
    "        if ( k == frame_no - 4):\n",
    "            frame_b4 = frame\n",
    "        if ( k == frame_no - 3):\n",
    "            frame_b3 = frame\n",
    "        if ( k == frame_no - 2):\n",
    "            frame_b2 = frame\n",
    "        if ( k == frame_no - 1):\n",
    "            frame_b1 = frame\n",
    "\n",
    "        if k == frame_no:\n",
    "            #boxes_list = [tuple(l) for l in boxes_list]\n",
    "            for i in range(n):\n",
    "                box = boxes_list[i]\n",
    "                x1[i] = (box[0]+2*box[2])/2\n",
    "                multiTracker_back.add(createTrackerByName(trackerType), frame, box)\n",
    "            \n",
    "            #all the vehicles from boxes_list added in the traker instance\n",
    "            #applying vehicle tracking in backward direction\n",
    "                \n",
    "            (success_back, boxes_back) = multiTracker_back.update(frame_b1)\n",
    "            (success_back, boxes_back) = multiTracker_back.update(frame_b2)\n",
    "            (success_back, boxes_back) = multiTracker_back.update(frame_b3)\n",
    "            (success_back, boxes_back) = multiTracker_back.update(frame_b4)\n",
    "            (success_back, boxes_back) = multiTracker_back.update(frame_b5)\n",
    "            #(success_back, boxes_back) = multiTracker_back.update(frame_b6)\n",
    "            #(success_back, boxes_back) = multiTracker_back.update(frame_b7)\n",
    "            #(success_back, boxes_back) = multiTracker_back.update(frame_b8)\n",
    "            #(success_back, boxes_back) = multiTracker_back.update(frame_b9)\n",
    "            #(success_back, boxes_back) = multiTracker_back.update(frame_b10)\n",
    "\n",
    "\n",
    "\n",
    "            for i in range(n):\n",
    "                    b = boxes_back[i]\n",
    "                    x2[i] = (b[0]+2*b[2])/2\n",
    "                    #print('x1',i,x1[i])\n",
    "\n",
    "\n",
    "            for i in range(n):\n",
    "                \n",
    "                x_d =  x2[i] - x1[i]\n",
    "                #print(x_d)\n",
    "                if x_d > 0:\n",
    "                    directions[i] = 1\n",
    "                elif x_d < 0:\n",
    "                    directions[i] = -1\n",
    "\n",
    "            for i in range(n):\n",
    "                box = boxes_list[i]\n",
    "                (x,y,w,h) = [int(v) for v in box]\n",
    "                if(directions[i] == 0): # not moving\n",
    "                    cv2.rectangle(frame, (x,y), (x+w,y+h), (255,0,0), 2)\n",
    "                elif(directions[i] == 1): # direction of interest\n",
    "                    cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "                elif(directions[i] == -1): # opposite to direction of interest\n",
    "                    cv2.rectangle(frame, (x,y), (x+w,y+h), (0,0,255), 2)\n",
    "\n",
    "            #cv2.imshow('frame', frame)\n",
    "            cv2.waitKey(0)\n",
    "            break\n",
    "        k = k+1\n",
    "        \n",
    "    cv2.destroyAllWindows()\n",
    "    return np.array(directions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 1  1 -1 -1 -1  1  1 -1 -1]\n[ 1  1  1 -1 -1 -1  1  1 -1  1 -1]\n"
     ]
    }
   ],
   "source": [
    "boxes_list = [(b[0],b[1],b[2]-b[0],b[3]-b[1]) for b in bboxes]\n",
    "\n",
    "c = get_direction(\"C:/RoadCrossingAssistant/Data/Videos/video1.MOV\", \"KCF\", boxes_list, 20)\n",
    "\n",
    "print(c)\n",
    "\n",
    "#x = np.load(\"C:/RoadCrossingAssistant/Data/Directions_RetinaNet/directions1.npy\", allow_pickle=True)\n",
    "#print(x[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speeds_from_frame(video, boxes_list, frame_no, no_previous_frames, trackerType = \"KCF\"):\n",
    "\n",
    "    '''\n",
    "    Detects speed of each vehicle in the frame and returns and an containing these speeds\n",
    "\n",
    "    Parameters:\n",
    "    video(string) : path of the video\n",
    "    frame_no : frame no of the video for which you require directions\n",
    "    boxes_list(list) : list containing bounding boxes for all detected vehicles in the particular frame\n",
    "    no_previous_frames(int) : number of previous frames to be considered while calculating the speed\n",
    "    trackerType(string) : the openCV tracker type to be used\n",
    "\n",
    "    '''\n",
    "    frame_buffer = []\n",
    "    #cv2.namedWindow(video, cv2.WINDOW_NORMAL)\n",
    "    #cv2.resizeWindow(video, height=650, width=1156)\n",
    "    cap = cv2.VideoCapture(video)\n",
    "\n",
    "    for i in range(frame_no - no_previous_frames, frame_no + 1):\n",
    "\n",
    "        cap.set(1,i)\n",
    "        ret, frame = cap.read()\n",
    "        frame_buffer.append(frame)\n",
    "\n",
    "    multiTracker_back = cv2.MultiTracker_create()\n",
    "    #multiTracker = cv2.MultiTracker_create()\n",
    "    n = len(boxes_list)\n",
    "    speeds = [0]*n\n",
    "    x1 = [0]*n  #x coordinates of vehicles in frame_no\n",
    "    y1 = [0]*n #y coordinates of vehicles in frame_no\n",
    "    x2 = [0]*n  #x coordinates of vehicles in frame_no - no_previous_frames\n",
    "    y2 = [0]*n #y coordinates of vehicles in frame_no - no_previous_frames\n",
    "\n",
    "    frame = frame_buffer.pop()\n",
    "    for i in range(n):\n",
    "        box = boxes_list[i]\n",
    "        x1[i] = (box[0]+2*box[2])/2\n",
    "        y1[i] = (box[1]+2*box[3])/2\n",
    "        multiTracker_back.add(createTrackerByName(trackerType), frame, box)\n",
    "        #all the vehicles from boxes_list added in the traker instance\n",
    "        #applying vehicle tracking in backward direction\n",
    "    for j in range(no_previous_frames):\n",
    "        frame = frame_buffer.pop()\n",
    "        (success_back, boxes_back) = multiTracker_back.update(frame)\n",
    "\n",
    "    for i in range(n):\n",
    "        b = boxes_back[i]\n",
    "        x2[i] = (b[0]+2*b[2])/2\n",
    "        y2[i] = (b[1]+2*b[3])/2\n",
    "        x_d = x2[i] - x1[i]\n",
    "        y_d = y2[i] - y1[i]\n",
    "        dist = (x_d**2 + y_d**2)**0.5\n",
    "        speeds[i] = dist\n",
    "\n",
    "    return np.array(speeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 12.          10.11187421   3.53553391   4.03112887  37.85498646\n  37.27264412 101.00495037  66.48308055   3.35410197]\n"
     ]
    }
   ],
   "source": [
    "s = get_speeds_from_frame(\"C:/RoadCrossingAssistant/Data/Videos/video1.MOV\", boxes_list, 20, 6)\n",
    "\n",
    "print(s)"
   ]
  }
 ]
}