{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach 1.3:**\n",
    "\n",
    "**Training:**\n",
    "\n",
    "-> For every selected frame of video, extract features and give label(label generated by converting manually marked safe duration into frame intervals)\n",
    "\n",
    "-> Use classification to predict 0/1 for each frame\n",
    "\n",
    "**Testing :**\n",
    "\n",
    "For every frame, extract features and use classification to predict label\n",
    "\n",
    "**Features to be extracted from individual frames:**\n",
    "\n",
    "Cummulative approach made after 1.2 with new improvement:\n",
    "- Changed labels.csv file from manually annotated videos **second-wise** to **frame-wise**, frame-wise annotations generated using frame-wise-annotations.ipynb file.\n",
    "- Added Relative speed of each vehicle as feature for all 6 regions (using saved speed arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#importing necessary libraries\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline  \n",
    "from imageai.Detection import VideoObjectDetection\n",
    "import os\n",
    "import sys\n",
    "from random import randint\n",
    "from math import ceil, sqrt\n",
    "import natsort\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn.model_selection import GridSearchCV \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'siddhi'\n",
    "\n",
    "if user == 'siddhi':\n",
    "    path_videos = 'C:/RoadCrossingAssistant/Data/Videos/'\n",
    "    path_detection_arrays = 'C:/RoadCrossingAssistant/Data/Arrays_RetinaNet/'\n",
    "    path_direction_arrays = 'C:/RoadCrossingAssistant/Data/Directions_RetinaNet/'\n",
    "    path_labels_csv = 'C:/RoadCrossingAssistant/Data/labels_framewise_csv.csv'\n",
    "    path_labels_list = 'C:/RoadCrossingAssistant/Data/labels_framewise_list.pkl'\n",
    "\n",
    "elif user == 'yagnesh':\n",
    "    path_videos = '/home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/videos/'\n",
    "    path_detection_arrays = '/home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/arrays/arrays_v2_RetinaNet/'\n",
    "    path_direction_arrays = '/home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/directions/directions_v2_RetinaNet/'\n",
    "    path_speed_arrays = '/home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/speeds/'\n",
    "    path_labels_csv = '/home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/labels_framewise.csv'\n",
    "    path_labels_list = '/home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/labels_framewise.pkl'\n",
    "\n",
    "\n",
    "detection_arrays = glob.glob(path_detection_arrays+'array*.npy')\n",
    "detection_arrays = natsort.natsorted(detection_arrays)\n",
    "#detection_arrays = np.array(detection_arrays)\n",
    "#print(detection_arrays)\n",
    "#print('shape of detection_arrays: ', detection_arrays.shape)\n",
    "\n",
    "direction_arrays = glob.glob(path_direction_arrays+'directions*.npy')\n",
    "direction_arrays = natsort.natsorted(direction_arrays)\n",
    "\n",
    "speed_arrays = glob.glob(path_speed_arrays+'speeds*.npy')\n",
    "speed_arrays = natsort.natsorted(speed_arrays)\n",
    "\n",
    "videos = glob.glob(path_videos+'video*.MOV')\n",
    "videos = natsort.natsorted(videos)\n",
    "#videos = np.array(videos)\n",
    "#print('shape of videos: ', videos.shape)\n",
    "\n",
    "open_file = open(path_labels_list, \"rb\")\n",
    "labels_list = pickle.load(open_file)\n",
    "open_file.close()\n",
    "#labels_list = np.array(labels_list)\n",
    "#print('labels_array: \\n ', labels_list[89])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "len of detection_arrays_train:  80\nlen of detection_arrays_test:  24\nlen of direction_arrays_train:  80\nlen of direction_arrays_test:  24\nlen of videos_train:  80\nlen of videos_test:  24\nlen of labels_train:  80\nlen of labels_test:  24\n"
     ]
    }
   ],
   "source": [
    "#Perform train-test split(78-26)\n",
    "\n",
    "x = np.arange(104)\n",
    "#np.random.seed(42)\n",
    "indices_test = np.random.choice(x, 24, replace=False)\n",
    "indices_train = np.delete(x, indices_test, axis=0)\n",
    "\n",
    "detection_arrays_train = [detection_arrays[ind] for ind in indices_train]\n",
    "detection_arrays_test = [detection_arrays[ind] for ind in indices_test]\n",
    "\n",
    "direction_arrays_train = [direction_arrays[ind] for ind in indices_train]\n",
    "direction_arrays_test = [direction_arrays[ind] for ind in indices_test]\n",
    "\n",
    "speed_arrays_train = [speed_arrays[ind] for ind in indices_train]\n",
    "speed_arrays_test = [speed_arrays[ind] for ind in indices_test]\n",
    "\n",
    "videos_train = [videos[ind] for ind in indices_train]\n",
    "videos_test = [videos[ind] for ind in indices_test]\n",
    "\n",
    "labels_train = [labels_list[ind] for ind in indices_train]\n",
    "labels_test = [labels_list[ind] for ind in indices_test]\n",
    "\n",
    "print('len of detection_arrays_train: ', len(detection_arrays_train))\n",
    "print('len of detection_arrays_test: ', len(detection_arrays_test))\n",
    "print('len of direction_arrays_train: ', len(direction_arrays_train))\n",
    "print('len of direction_arrays_test: ', len(direction_arrays_test))\n",
    "print('len of speed_arrays_train: ', len(speed_arrays_train))\n",
    "print('len of speed_arrays_test: ', len(speed_arrays_test))\n",
    "print('len of videos_train: ', len(videos_train))\n",
    "print('len of videos_test: ', len(videos_test))\n",
    "print('len of labels_train: ', len(labels_train))\n",
    "print('len of labels_test: ', len(labels_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_region(x,y):\n",
    "\n",
    "    '''\n",
    "    Returns the region in which the particular point lies\n",
    "\n",
    "    Parameters:\n",
    "    x(int) : x coordinate of the point\n",
    "    y(int) : y coordinate of the point\n",
    "\n",
    "    Returns:\n",
    "    int : region no (1/2/3/4/5/6)\n",
    "    '''\n",
    "\n",
    "    video_height = 1080\n",
    "    video_width = 1920\n",
    "\n",
    "    if(x<640 and y>=540):\n",
    "        return 1 #Bottom left region\n",
    "    if(x<=1280 and y>=540):\n",
    "        return 2 #Bottom center region\n",
    "    if(x>1280 and y>=540):\n",
    "        return 3 #Bottom right region\n",
    "    if(x>1280 and y<540):\n",
    "        return 4 #Top right region\n",
    "    if(x<=1280 and y<540):\n",
    "        return 5 #Top center region\n",
    "    if(x<640 and y<540):\n",
    "        return 6 #Top left region\n",
    "\n",
    "def extract_features_from_frame(bounding_boxes, directions_for_boxes, speed_for_boxes, frame_no):\n",
    "        \n",
    "    '''\n",
    "    Extract features from a particular frame\n",
    "\n",
    "    Parameters:\n",
    "    bounding_boxes(array) : detection array of the video\n",
    "    direction_for_boxes(array) : detection of direction for all bounding boxes \n",
    "    speed_for_boxes(array) : calculated speed arrays for all bounding boxes\n",
    "    frame_no(int) : frame no for which features are to be extracted\n",
    "\n",
    "    Returns:\n",
    "    list : containing 24 features of the frame\n",
    "    '''    \n",
    "\n",
    "    no_of_boxes = len(bounding_boxes[frame_no])  # total number of bounding boxes\n",
    "    boxes_frame = np.array(bounding_boxes[frame_no]) # bounding boxes for each frame \n",
    "    direction_frame = np.array(directions_for_boxes[frame_no]) # directions for every bounding boxes\n",
    "    speed_frame = np.array(speed_for_boxes[frame_no]) # speed array for every bounding boxes\n",
    "\n",
    "    # checking if no of bounding boxes and direction array length matches or not \n",
    "    if len(direction_frame) != no_of_boxes or len(speed_frame) != no_of_boxes:\n",
    "        raise Exception('mismatch in number of boxes \\n Direction Frame Length:'+ str(len(direction_frame))+'\\n Speed Frame Length:' + str(len(speed_frame))+ '\\n Total number of bounding boxes:' +str(no_of_boxes))\n",
    "\n",
    "    # matching indices of bounding boxes with required directions array\n",
    "    indices_required_boxes = np.where(direction_frame>=0)[0] # getting direction indices which is having value 0 or 1 (steady or positive direction vehicle)\n",
    "\n",
    "    # assigning indices of interested direction values (0 and 1 value of directions)\n",
    "    required_speed_frame = speed_frame[indices_required_boxes]\n",
    "    boxes_required = boxes_frame[indices_required_boxes]\n",
    "\n",
    "    # feature - number of vehicles in each region\n",
    "    r1 = r2 = r3 = r4 = r5 = r6 = 0\n",
    "    \n",
    "    # feature - total area of vehicles in each region\n",
    "    r1_area = r2_area = r3_area = r4_area = r5_area = r6_area = 0\n",
    "\n",
    "    # distance calculation for every region\n",
    "    bottom_center_point_x = 1920/2    # width/2\n",
    "    bottom_center_point_y = 1080      # height\n",
    "    #feature - minimum distance of the vechiles from every region to origin point (bottom-center point)\n",
    "    r1_min_distance = r2_min_distance = r3_min_distance = r4_min_distance = r5_min_distance = r6_min_distance = 0\n",
    "\n",
    "    # feature - Maximum speed of the vehicles from every region\n",
    "    r1_max_speed = r2_max_speed = r3_max_speed = r4_max_speed = r5_max_speed = r6_max_speed = 0.0\n",
    "    temp_speed = 0.0\n",
    "\n",
    "    for j in range(len(boxes_required)):\n",
    "\n",
    "        # center x coordinate of bounding box cx\n",
    "        cx = (boxes_required[j][0] + boxes_required[j][2])/2\n",
    "\n",
    "        # center y coordinate of bounding box cy\n",
    "        cy = (boxes_required[j][1] + boxes_required[j][3])/2\n",
    "\n",
    "        # area of bounding box\n",
    "        bounding_box_area = ((boxes_required[j][3]-boxes_required[j][1])*\n",
    "                        (boxes_required[j][2]-boxes_required[j][0]))\n",
    "\n",
    "        # initial speed for frame\n",
    "        temp_speed = required_speed_frame[j][0]\n",
    "\n",
    "        # distance calculation for every bounding box\n",
    "        distance = sqrt((cx - bottom_center_point_x)**2 + (cy - bottom_center_point_y)**2)\n",
    "\n",
    "        # finding region according to cx,cy and finding total area, minimum distance and maximum speed for each region\n",
    "        if(find_region(cx,cy)==1):\n",
    "            r1 = r1 + 1\n",
    "            r1_area = r1_area + bounding_box_area\n",
    "            if(r1_min_distance==0 or distance < r1_min_distance):\n",
    "                r1_min_distance = distance\n",
    "            if(r1_max_speed > temp_speed):\n",
    "                r1_max_speed = temp_speed\n",
    "        elif(find_region(cx,cy)==2):\n",
    "            r2 = r2 + 1\n",
    "            r2_area = r2_area + bounding_box_area\n",
    "            if(r2_min_distance==0 or distance < r2_min_distance):\n",
    "                r2_min_distance = distance\n",
    "            if(r2_max_speed > temp_speed):\n",
    "                r2_max_speed = temp_speed\n",
    "        elif(find_region(cx,cy)==3):\n",
    "            r3 = r3 + 1\n",
    "            r3_area = r3_area + bounding_box_area\n",
    "            if(r3_min_distance==0 or distance < r3_min_distance):\n",
    "                r3_min_distance = distance\n",
    "            if(r3_max_speed > temp_speed):\n",
    "                r3_max_speed = temp_speed\n",
    "        elif(find_region(cx,cy)==4):\n",
    "            r4 = r4 + 1\n",
    "            r4_area = r4_area + bounding_box_area\n",
    "            if(r4_min_distance==0 or distance < r4_min_distance):\n",
    "                r4_min_distance = distance\n",
    "            if(r4_max_speed > temp_speed):\n",
    "                r4_max_speed = temp_speed\n",
    "        elif(find_region(cx,cy)==5):\n",
    "            r5 = r5 + 1\n",
    "            r5_area = r5_area + bounding_box_area\n",
    "            if(r5_min_distance==0 or distance < r5_min_distance):\n",
    "                r5_min_distance = distance\n",
    "            if(r5_max_speed > temp_speed):\n",
    "                r5_max_speed = temp_speed\n",
    "        elif(find_region(cx,cy)==6):\n",
    "            r6 = r6 + 1\n",
    "            r6_area = r6_area + bounding_box_area\n",
    "            if(r6_min_distance==0 or distance < r6_min_distance):\n",
    "                r6_min_distance = distance\n",
    "            if(r6_max_speed > temp_speed):\n",
    "                r6_max_speed = temp_speed\n",
    "                \n",
    "    features_frame = [r1,r1_area,r1_min_distance,r1_max_speed,r2,r2_area,r2_min_distance,r2_max_speed,r3,r3_area,r3_min_distance,r3_max_speed,r4,r4_area,r4_min_distance,r4_max_speed,r5,r5_area,r5_min_distance,r5_max_speed,r6,r6_area,r6_min_distance,r6_max_speed]  # final frame with 18 features\n",
    "        \n",
    "    return features_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_from_video(no_frames, safe_duration_list):\n",
    "    \n",
    "    '''\n",
    "    Get labels for a particular video \n",
    "\n",
    "    Parameters:\n",
    "    no_frames(int) : no of frames in the given video\n",
    "    safe_duration_list(list) : a list of the type [safe_start1, safe_end1, safe_start2, safe_end2,......]\n",
    "\n",
    "    Returns:\n",
    "    list : list with len = no of frames and the value at each index represents safe/unsafe at that frame_no (frame_no starting at 0)\n",
    "    int : -1 if there is no safe duration in video, 1 otherwise\n",
    "    '''\n",
    "\n",
    "    labels = [0]*no_frames\n",
    "    no_safe_durations = int(len(safe_duration_list)/2)\n",
    "    if(no_safe_durations == 0):\n",
    "        return labels,-1 # there is no safe duration in the given video so all labels marked 0\n",
    "    else:\n",
    "\n",
    "        for i in range(no_safe_durations):\n",
    "            safe_start = max(safe_duration_list[i*2] - 1, 0)\n",
    "            safe_end = min(safe_duration_list[i*2 +1] - 1, no_frames-1)\n",
    "            labels[safe_start:safe_end+1] = [1]*(safe_end-safe_start+1) # marking the value b/w safe_start and safe_end with 1\n",
    "\n",
    "    if len(labels) > no_frames: #len of labels cannot be greater than no_frames in video\n",
    "        raise Exception('Check the labels assigned in CSV file!')\n",
    "    return labels,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataframe(indices):\n",
    "\n",
    "    '''\n",
    "    Generate dataframes for model training\n",
    "\n",
    "    Parameters:\n",
    "    indices(list) : indices_train for generating training dataframes, indices_test for generating testing dataframes\n",
    "\n",
    "    Returns:\n",
    "    features_dataframe : dataframe containg 24 features per frame\n",
    "    labels_dataframe : dataframe containing 1 label per frame\n",
    "    '''\n",
    "\n",
    "\n",
    "    cols_f = ['region1','region1_area','region1_min_distance','region1_max_speed','region2','region2_area','region2_min_distance','region2_max_speed','region3','region3_area','region3_min_distance','region3_max_speed','region4','region4_area','region4_min_distance','region4_max_speed','region5','region5_area','region5_min_distance','region5_max_speed','region6','region6_area','region6_min_distance','region6_max_speed'] # 24 features per frame\n",
    "\n",
    "    cols_l = ['safe/unsafe'] #1 label per frame\n",
    "    features_dataframe = pd.DataFrame()\n",
    "    labels_dataframe = pd.DataFrame()\n",
    "\n",
    "    for ind in indices:\n",
    "\n",
    "        fname = detection_arrays[ind]\n",
    "        dname = direction_arrays[ind]\n",
    "        sname = speed_arrays[ind]\n",
    "        safe_duration_list = labels_list[ind]\n",
    "\n",
    "        print(\"processing \",fname)\n",
    "        bounding_boxes = np.load(fname, allow_pickle=True) #loading the numpy array containing all detected vehicles\n",
    "        directions_for_boxes = np.load(dname, allow_pickle=True) # loading the arrays containing detected directions for each bounding box\n",
    "        speed_for_boxes = np.load(sname, allow_pickle=True) # loading the arrays containing calculated speed for each bounding box\n",
    "\n",
    "        no_frames = bounding_boxes.shape[0]\n",
    "        #print(\"no of frames: \", no_frames)\n",
    "        labels, flag = get_labels_from_video(no_frames, safe_duration_list)\n",
    "        #print('flag', flag)\n",
    "\n",
    "        labels_0 = [i for i, value in enumerate(labels) if value == 0 and i>6]\n",
    "        # shuffling unsafe frames\n",
    "        random.shuffle(labels_0)\n",
    "        # selecting 50 frames from unsafe videos instead of rejecting the whole video\n",
    "        if(len(labels_0) >= 50): \n",
    "            labels_0 = labels_0[:50]\n",
    "\n",
    "        if(flag == -1):\n",
    "            #print('no safe time')\n",
    "            labels_1 = []\n",
    "        else:\n",
    "            labels_1 = [i for i, value in enumerate(labels) if value == 1 and i>6]\n",
    "            # shuffling safe frames\n",
    "            random.shuffle(labels_1)\n",
    "            ## selecting no of safe frames = no of unsafe frames from each video ##\n",
    "            # label 0 frames will be more than label 1 frame, \n",
    "            # so we will try to select same number of safe and unsafe frames\n",
    "            if(len(labels_0) >= len(labels_1)):\n",
    "                labels_0 = labels_0[:len(labels_1)]\n",
    "\n",
    "        features = []\n",
    " \n",
    "\n",
    "        for frame_no in labels_0:\n",
    "            features_frame = extract_features_from_frame(bounding_boxes, directions_for_boxes, speed_for_boxes, frame_no)\n",
    "            features.append(features_frame)\n",
    "        for frame_no in labels_1:\n",
    "            features_frame = extract_features_from_frame(bounding_boxes, directions_for_boxes, speed_for_boxes, frame_no)\n",
    "            features.append(features_frame)\n",
    "        \n",
    "        # generating and returning features and labels dataframes\n",
    "        no_frames_in_features = len(features)\n",
    "        #print(\"no_frames_in_features\",no_frames_in_features)\n",
    "        labels = [0]*len(labels_0) + [1]*len(labels_1)\n",
    "        #print(\"no_of_frames_in_labels\", len(labels))\n",
    "        df1 = pd.DataFrame(features, columns=cols_f)\n",
    "        features_dataframe = features_dataframe.append(df1,ignore_index=True)\n",
    "        print(\"df1.size\",df1.shape)\n",
    "        df2 = pd.DataFrame(labels, columns=cols_l)\n",
    "        labels_dataframe = labels_dataframe.append(df2,ignore_index=True)\n",
    "        #print(\"df2.size\",df2.shape)\n",
    "        \n",
    "    return features_dataframe, labels_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modified function in terms of selection of frames\n",
    "\n",
    "def generate_dataframe(indices, reduce):\n",
    "\n",
    "    '''\n",
    "    Generate dataframes for model training\n",
    "\n",
    "    Parameters:\n",
    "    indices(list) : indices_train for generating training dataframes, indices_test for generating testing dataframes\n",
    "    reduce(bool) : True to reduce dataframe size to maintain safe/unsafe ratio, else False\n",
    "\n",
    "    Returns:\n",
    "    features_dataframe : dataframe containg 24 features per frame\n",
    "    labels_dataframe : dataframe containing 1 label per frame\n",
    "    '''\n",
    "\n",
    "\n",
    "    cols_f = ['region1','region1_area','region1_min_distance','region1_max_speed','region2','region2_area','region2_min_distance','region2_max_speed','region3','region3_area','region3_min_distance','region3_max_speed','region4','region4_area','region4_min_distance','region4_max_speed','region5','region5_area','region5_min_distance','region5_max_speed','region6','region6_area','region6_min_distance','region6_max_speed'] # 24 features per frame\n",
    "\n",
    "    cols_l = ['safe/unsafe'] # 1 label per frame\n",
    "    features_dataframe = pd.DataFrame()\n",
    "    labels_dataframe = pd.DataFrame()\n",
    "\n",
    "    for ind in indices:\n",
    "\n",
    "        fname = detection_arrays[ind]\n",
    "        dname = direction_arrays[ind]\n",
    "        sname = speed_arrays[ind]\n",
    "        safe_duration_list = labels_list[ind]\n",
    "\n",
    "        print(\"processing \",fname)\n",
    "        bounding_boxes = np.load(fname, allow_pickle=True) # loading the numpy array containing all detected vehicles\n",
    "        directions_for_boxes = np.load(dname, allow_pickle=True) # loading the arrays containing detected directions for each bounding box\n",
    "        speed_for_boxes = np.load(sname, allow_pickle=True) # loading the arrays containing speed for each bounding box\n",
    "\n",
    "        no_frames = bounding_boxes.shape[0]\n",
    "        #print(\"no of frames: \", no_frames)\n",
    "        labels, flag = get_labels_from_video(no_frames, safe_duration_list)\n",
    "        labels = labels[6:]\n",
    "        #print('flag', flag)\n",
    "\n",
    "        #labels_0 = [i for i, value in enumerate(labels) if value == 0]\n",
    "        # shuffling unsafe frames\n",
    "        #random.shuffle(labels_0)\n",
    "        # selecting 50 frames from unsafe videos instead of rejecting the whole video\n",
    "        #if(len(labels_0) >= 50): \n",
    "        #    labels_0 = labels_0[:50]\n",
    "\n",
    "        #if(flag == -1):\n",
    "        #    #print('no safe time')\n",
    "        #    labels_1 = []\n",
    "        # else:\n",
    "        #     labels_1 = [i for i, value in enumerate(labels) if value == 1]\n",
    "        #     # shuffling safe frames\n",
    "        #     random.shuffle(labels_1)\n",
    "        #     ## selecting no of safe frames = no of unsafe frames from each video ##\n",
    "        #     # label 0 frames will be more than label 1 frame, \n",
    "        #     # so we will try to select same number of safe and unsafe frames\n",
    "        #     if(len(labels_0) >= len(labels_1)):\n",
    "        #         labels_0 = labels_0[:len(labels_1)]\n",
    "\n",
    "        features = []\n",
    " \n",
    "        for frame_no in range(6, no_frames):\n",
    "            features_frame = extract_features_from_frame(bounding_boxes, directions_for_boxes, speed_for_boxes,frame_no)\n",
    "            features.append(features_frame)\n",
    "        \n",
    "        #generating and returning features and labels dataframes\n",
    "        no_frames_in_features = len(features)\n",
    "        #print(\"no_frames_in_features\",no_frames_in_features)\n",
    "        #labels = [0]*len(labels_0) + [1]*len(labels_1)\n",
    "        #print(\"no_of_frames_in_labels\", len(labels))\n",
    "        df1 = pd.DataFrame(features, columns=cols_f)\n",
    "        features_dataframe = features_dataframe.append(df1,ignore_index=True)\n",
    "        #print(\"df1.size\",df1.shape)\n",
    "        df2 = pd.DataFrame(labels, columns=cols_l)\n",
    "        labels_dataframe = labels_dataframe.append(df2,ignore_index=True)\n",
    "        #print(\"df2.size\",df2.shape)\n",
    "    \n",
    "    if reduce == True:\n",
    "        ind0 = labels_dataframe.index[labels_dataframe['safe/unsafe'] == 0].tolist()\n",
    "        random.shuffle(ind0)\n",
    "        ind1 = labels_dataframe.index[labels_dataframe['safe/unsafe'] == 1].tolist()\n",
    "        random.shuffle(ind1)\n",
    "        print(len(ind0)/len(ind1))\n",
    "        if (len(ind0)/len(ind1)) > 1.2:\n",
    "            print('reducing the number of unsafe frames in dataframe\\n\\n')\n",
    "            len_ind0 = int(len(ind1)*1.2)\n",
    "            ind0 = ind0[:len_ind0]\n",
    "\n",
    "            indices_required = ind0 + ind1\n",
    "            features_dataframe = features_dataframe.iloc[indices_required]\n",
    "            labels_dataframe = labels_dataframe.iloc[indices_required]\n",
    "        \n",
    "    return features_dataframe, labels_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array1.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array2.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array3.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array4.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array5.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array6.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array7.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array8.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array9.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array10.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array11.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array12.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array13.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array14.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array15.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array17.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array18.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array19.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array20.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array21.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array22.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array23.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array24.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array25.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array26.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array27.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array29.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array30.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array32.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array33.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array34.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array36.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array38.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array39.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array40.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array42.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array46.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array48.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array49.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array50.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array51.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array52.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array54.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array55.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array56.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array59.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array60.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array62.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array63.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array64.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array65.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array68.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array69.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array71.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array72.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array73.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array76.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array77.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array79.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array80.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array81.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array82.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array83.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array84.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array85.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array87.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array88.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array89.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array92.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array93.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array94.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array95.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array96.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array97.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array99.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array100.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array101.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array102.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array103.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array104.npy\n",
      "1.8567367822626493\n",
      "reducing the number of unsafe frames in dataframe\n",
      "\n",
      "\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array91.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array45.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array66.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array74.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array70.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array78.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array75.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array57.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array44.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array86.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array61.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array28.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array67.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array37.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array41.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array31.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array90.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array98.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array43.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array47.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array16.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array53.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array58.npy\n",
      "processing  C:/RoadCrossingAssistant/Data/Arrays_RetinaNet\\array35.npy\n",
      "features_df_train.shape:  (15479, 18)\n",
      "labels_df_train.shape:  (15479, 1)\n",
      "features_df_test.shape:  (5796, 18)\n",
      "labels_df_test.shape:  (5796, 1)\n"
     ]
    }
   ],
   "source": [
    "features_df_train, labels_df_train = generate_dataframe(indices_train, True)\n",
    "# features_df_train.to_pickle('features_df_train.pkl')\n",
    "# labels_df_train.to_pickle('labels_df_train.pkl')\n",
    "\n",
    "features_df_test, labels_df_test = generate_dataframe(indices_test, False)\n",
    "# features_df_test.to_pickle('features_df_test.pkl')\n",
    "# labels_df_test.to_pickle('labels_df_test.pkl')\n",
    "print(\"features_df_train.shape: \", features_df_train.shape)\n",
    "print(\"labels_df_train.shape: \", labels_df_train.shape)\n",
    "\n",
    "print(\"features_df_test.shape: \", features_df_test.shape)\n",
    "print(\"labels_df_test.shape: \", labels_df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# StandardScaler\n",
    "#feature_scaler = StandardScaler()\n",
    "\n",
    "# MinMaxScaler\n",
    "feature_scaler = MinMaxScaler()\n",
    "\n",
    "# storing scaled features\n",
    "features_train_scaled = pd.DataFrame(feature_scaler.fit_transform(features_df_train))\n",
    "features_train_scaled.columns = ['region1','region1_area','region1_min_distance','region1_max_speed','region2','region2_area','region2_min_distance','region2_max_speed','region3','region3_area','region3_min_distance','region3_max_speed','region4','region4_area','region4_min_distance','region4_max_speed','region5','region5_area','region5_min_distance','region5_max_speed','region6','region6_area','region6_min_distance','region6_max_speed']\n",
    "features_test_scaled = pd.DataFrame(feature_scaler.transform(features_df_test))\n",
    "features_test_scaled.columns = ['region1','region1_area','region1_min_distance','region1_max_speed','region2','region2_area','region2_min_distance','region2_max_speed','region3','region3_area','region3_min_distance','region3_max_speed','region4','region4_area','region4_min_distance','region4_max_speed','region5','region5_area','region5_min_distance','region5_max_speed','region6','region6_area','region6_min_distance','region6_max_speed']"
   ]
  },
  {
   "source": [
    "## Model Training\n",
    "### Classification model: Support Vector Machine with rbf kernel"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "for train data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.81      8443\n",
      "           1       0.77      0.82      0.79      7036\n",
      "\n",
      "    accuracy                           0.80     15479\n",
      "   macro avg       0.80      0.80      0.80     15479\n",
      "weighted avg       0.81      0.80      0.80     15479\n",
      "\n",
      "accuracy score 0.8028942438141999\n",
      "\n",
      "for test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      3871\n",
      "           1       0.67      0.63      0.65      1925\n",
      "\n",
      "    accuracy                           0.77      5796\n",
      "   macro avg       0.74      0.73      0.74      5796\n",
      "weighted avg       0.77      0.77      0.77      5796\n",
      "\n",
      "accuracy score 0.7715665976535542\n"
     ]
    }
   ],
   "source": [
    "# scaled dataset\n",
    "model = SVC()\n",
    "model.fit(features_train_scaled, labels_df_train) \n",
    "from sklearn.metrics import accuracy_score\n",
    " \n",
    "# print prediction results \n",
    "print(\"for train data:\")\n",
    "predictions = model.predict(features_train_scaled) \n",
    "print(classification_report(labels_df_train, predictions)) \n",
    "print(\"accuracy score\", accuracy_score(labels_df_train, predictions))\n",
    "\n",
    "print(\"\\nfor test data:\")\n",
    "predictions = model.predict(features_test_scaled) \n",
    "print(classification_report(labels_df_test, predictions)) \n",
    "print(\"accuracy score\",accuracy_score(labels_df_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'path_direction_test_arrays' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-2ee3060f7c9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0maname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_detection_arrays\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/array62.npy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mvname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/video62.MOV\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mdname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_direction_test_arrays\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/directions62.npy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0mframe_no\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;36m160\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'path_direction_test_arrays' is not defined"
     ]
    }
   ],
   "source": [
    "# checking predictions for individual frames\n",
    "\n",
    "def prediction_for_frame(aname, dname, frame_no ):\n",
    "\n",
    "    bounding_boxes = np.load(aname, allow_pickle=True)\n",
    "    dirs = np.load(dname, allow_pickle=True)\n",
    "\n",
    "    features = extract_features_from_frame(bounding_boxes, dirs, frame_no)\n",
    "\n",
    "    f = []\n",
    "    f.append(features)\n",
    "    cols_f = ['region1','region1_area','region1_min_distance','region1_max_speed','region2','region2_area','region2_min_distance','region2_max_speed','region3','region3_area','region3_min_distance','region3_max_speed','region4','region4_area','region4_min_distance','region4_max_speed','region5','region5_area','region5_min_distance','region5_max_speed','region6','region6_area','region6_min_distance','region6_max_speed'] # 24 features per frame\n",
    "    f_df = pd.DataFrame(f, columns=cols_f)\n",
    "\n",
    "    f_df_scaled = pd.DataFrame(feature_scaler.transform(f_df))\n",
    "    f_df_scaled.columns = cols_f\n",
    "\n",
    "    print(\"prediction: \",model.predict(f_df_scaled))\n",
    "\n",
    "def show_frame(vname, frame_no): \n",
    "      \n",
    "    # Path to video file \n",
    "    vidObj = cv2.VideoCapture(vname) \n",
    "    # Used as counter variable \n",
    "    count = 0\n",
    "    # checks whether frames were extracted \n",
    "    success = 1\n",
    "  \n",
    "    while success: \n",
    "  \n",
    "        # vidObj object calls read \n",
    "        # function extract frames \n",
    "        success, image = vidObj.read() \n",
    "        if(count == frame_no):\n",
    "        # Saves the frames with frame-count \n",
    "            cv2.imwrite(\"frame%d.jpg\" % count, image)\n",
    "            break \n",
    "  \n",
    "        count += 1\n",
    "\n",
    "\n",
    "aname = path_detection_arrays + \"/array62.npy\"\n",
    "vname = \"/home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/video62.MOV\"\n",
    "dname = path_direction_test_arrays + \"/directions62.npy\"\n",
    "frame_no  = 160\n",
    "\n",
    "prediction_for_frame(aname, dname, frame_no)\n",
    "show_frame(vname, frame_no)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python37364bitroadcrossconda9373e858eb374c278c9e03a6646bb46c",
   "display_name": "Python 3.7.3 64-bit ('roadcross': conda)",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}