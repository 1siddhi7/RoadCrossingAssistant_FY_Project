{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit ('roadcross': conda)",
   "metadata": {
    "interpreter": {
     "hash": "efbaad368bcd49cf5b8b1d4bc08527738fe3c05d47d6e3ea110540aa6c36949d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import glob\n",
    "from imageai.Detection import VideoObjectDetection\n",
    "import natsort\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from imageai.Detection import VideoObjectDetection\n",
    "import os\n",
    "import sys\n",
    "from random import randint\n",
    "from math import ceil, nan, sqrt\n",
    "import natsort\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sys\n",
    "import cv2\n",
    "from random import randint\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numbers_from_filename(filename):\n",
    "    'utility function to get first number from a file name'\n",
    "    return re.search(r'\\d+', filename).group(0)\n",
    "\n",
    "trackerTypes = ['BOOSTING', 'MIL', 'KCF','TLD', 'MEDIANFLOW', 'GOTURN', 'MOSSE', 'CSRT']\n",
    "\n",
    "def createTrackerByName(trackerType):\n",
    "    \n",
    "  # Create a tracker based on tracker name\n",
    "    if trackerType == trackerTypes[0]:\n",
    "        tracker = cv2.TrackerBoosting_create()\n",
    "  \n",
    "    elif trackerType == trackerTypes[1]: \n",
    "        tracker = cv2.TrackerMIL_create()\n",
    "   \n",
    "    elif trackerType == trackerTypes[2]:\n",
    "        tracker = cv2.TrackerKCF_create()\n",
    "  \n",
    "    elif trackerType == trackerTypes[3]:\n",
    "        tracker = cv2.TrackerTLD_create()\n",
    "   \n",
    "    elif trackerType == trackerTypes[4]:\n",
    "        tracker = cv2.TrackerMedianFlow_create()\n",
    "    \n",
    "    elif trackerType == trackerTypes[5]:\n",
    "        tracker = cv2.TrackerGOTURN_create()\n",
    "            \n",
    "    elif trackerType == trackerTypes[6]:\n",
    "        tracker = cv2.TrackerMOSSE_create()\n",
    "        \n",
    "    elif trackerType == trackerTypes[7]:\n",
    "        tracker = cv2.TrackerCSRT_create()\n",
    "        \n",
    "    else:\n",
    "        tracker = None\n",
    "        print('Incorrect tracker name')\n",
    "        print('Available trackers are:')\n",
    "        for t in trackerTypes:\n",
    "            print(t)\n",
    "     \n",
    "    return tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speeds_from_frame(video, boxes_list, frame_no, no_previous_frames, trackerType = \"KCF\"):\n",
    "\n",
    "    '''\n",
    "    Detects speed of each vehicle in the frame and returns and a list \n",
    "    containing these speeds\n",
    "\n",
    "    Parameters:\n",
    "    videoPath(string) : path of the video\n",
    "    trackerType(string) : the openCV tracker type to be used  \n",
    "    boxes_list(list) : list containing bounding boxes for all detected vehicles in the particular frame\n",
    "    frame_no : frame no of the video for which you require directions\n",
    "\n",
    "    '''\n",
    "    frame_buffer = []\n",
    "    #cv2.namedWindow(video, cv2.WINDOW_NORMAL)\n",
    "    #cv2.resizeWindow(video, height=650, width=1156)\n",
    "    cap = cv2.VideoCapture(video)\n",
    "\n",
    "    for i in range(frame_no - no_previous_frames, frame_no + 1):\n",
    "\n",
    "        cap.set(1,i)\n",
    "        ret, frame = cap.read()\n",
    "        frame_buffer.append(frame)\n",
    "\n",
    "    multiTracker_back = cv2.MultiTracker_create()\n",
    "    #multiTracker = cv2.MultiTracker_create()\n",
    "    n = len(boxes_list)\n",
    "    speeds = [0]*n\n",
    "    x1 = [0]*n  #x coordinates of vehicles in frame_no\n",
    "    y1 = [0]*n #y coordinates of vehicles in frame_no\n",
    "    x2 = [0]*n  #x coordinates of vehicles in frame_no - no_previous_frames\n",
    "    y2 = [0]*n #y coordinates of vehicles in frame_no - no_previous_frames\n",
    "\n",
    "    frame = frame_buffer.pop()\n",
    "    for i in range(n):\n",
    "        box = boxes_list[i]\n",
    "        x1[i] = (box[0]+2*box[2])/2\n",
    "        y1[i] = (box[1]+2*box[3])/2\n",
    "        multiTracker_back.add(createTrackerByName(trackerType), frame, box)\n",
    "        #all the vehicles from boxes_list added in the traker instance\n",
    "        #applying vehicle tracking in backward direction\n",
    "    for j in range(no_previous_frames):\n",
    "        frame = frame_buffer.pop()\n",
    "        (success_back, boxes_back) = multiTracker_back.update(frame)\n",
    "\n",
    "    for i in range(n):\n",
    "        b = boxes_back[i]\n",
    "        x2[i] = (b[0]+2*b[2])/2\n",
    "        y2[i] = (b[1]+2*b[3])/2\n",
    "        x_d = x2[i] - x1[i]\n",
    "        y_d = y2[i] - y1[i]\n",
    "        dist = (x_d**2 + y_d**2)**0.5\n",
    "        speeds[i] = dist\n",
    "\n",
    "    return np.array(speeds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speeds_from_video(video, detection_array, target_folder, no_previous_frames = 5):\n",
    "\n",
    "    boxes_array = np.load(detection_array, allow_pickle=True)\n",
    "    no_frames = boxes_array.shape[0]\n",
    "    print(\"no_frames: \", no_frames)\n",
    "    findex = get_numbers_from_filename(video)\n",
    "    S = []\n",
    "    for i in range(no_previous_frames):\n",
    "        S.append([])\n",
    "\n",
    "    for frame_no in range(5, no_frames):\n",
    "        print(\"processing frame_no: \", frame_no)\n",
    "\n",
    "        temp = boxes_array[frame_no]\n",
    "        boxes_list = [(b[0],b[1],b[2]-b[0],b[3]-b[1]) for b in temp]\n",
    "\n",
    "        speeds = get_speeds_from_frame(video, boxes_list, frame_no, no_previous_frames)\n",
    "        S.append(speeds)\n",
    "            \n",
    "    S = np.array(S)\n",
    "    print('saving speeds for video' + video)\n",
    "    np.save(target_folder+'speeds'+str(findex),S)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vname = \"C:/RoadCrossingAssistant/Data/Videos/video1.MOV\"\n",
    "fname = \"C:/RoadCrossingAssistant/Data/Arrays_RetinaNet/array1.npy\"\n",
    "\n",
    "bounding_boxes = np.load(fname, allow_pickle=True) #loading the numpy array containing all detected vehicles\n",
    "no_frames = bounding_boxes.shape[0]\n",
    "\n",
    "frame_no = 35\n",
    "temp = bounding_boxes[frame_no]\n",
    "boxes_list = [(b[0],b[1],b[2]-b[0],b[3]-b[1]) for b in temp]\n",
    "\n",
    "#print(get_speed_from_frame(vname, \"KCF\", boxes_list, frame_no))\n",
    "get_speeds_from_video(vname, fname, 'C:/RoadCrossingAssistant/Data/Speeds_RetinaNet/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vname = \"C:/RoadCrossingAssistant/Data/Videos/video1.MOV\"\n",
    "\n",
    "cv2.namedWindow('video', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('video', height=650, width=1156)\n",
    "\n",
    "cap = cv2.VideoCapture(vname) #video_name is the video being called\n",
    "cap.set(1,25); # Where frame_no is the frame you want\n",
    "ret, frame = cap.read() # Read the frame\n",
    "cv2.imshow('video', frame) # show frame on window\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_speeds_video(video, detection_array, speeds_array):\n",
    "\n",
    "    cap = cv2.VideoCapture(video)\n",
    "    cv2.namedWindow(video, cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(video, height=650, width=1156)\n",
    "    no_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    detection_array = np.load(detection_array, allow_pickle=True)\n",
    "    speeds_array = np.load(speeds_array,allow_pickle=True)\n",
    "\n",
    "    frame_count = -1\n",
    "\n",
    "    while(cap.isOpened()):\n",
    "\n",
    "        success,frame = cap.read()\n",
    "        #print(i)\n",
    "\n",
    "        if success == True:\n",
    "\n",
    "            if(frame_count == -1):\n",
    "                while True:\n",
    "\n",
    "                    key_init = cv2.waitKey(25)\n",
    "                    cv2.imshow(video, frame)\n",
    "\n",
    "                    if key_init == ord('a'):\n",
    "                        break\n",
    "\n",
    "            frame_count = frame_count + 1\n",
    "\n",
    "            speeds_frame = speeds_array[frame_count]\n",
    "            temp = detection_array[frame_count]\n",
    "            boxes_frame = [(b[0],b[1],b[2]-b[0],b[3]-b[1]) for b in temp]\n",
    "            no_boxes = len(boxes_frame)\n",
    "\n",
    "            if(frame_count < 6):\n",
    "\n",
    "                for i in range(no_boxes):\n",
    "                    box = boxes_frame[i]\n",
    "                    (x,y,w,h) = [int(v) for v in box]\n",
    "                    cv2.rectangle(frame, (x,y), (x+w,y+h), (255,0,0), 2)\n",
    "\n",
    "                cv2.imshow(video, frame)\n",
    "                cv2.waitKey(100)        \n",
    "\n",
    "            else:\n",
    "                if(len(speeds_frame) != len(boxes_frame)):\n",
    "                    raise Exception(\"mismatch in length of speeds_frame and boxes_frame\")\n",
    "                \n",
    "                for i in range(no_boxes):\n",
    "                    box = boxes_frame[i]\n",
    "                    (x,y,w,h) = [int(v) for v in box]\n",
    "                    cv2.rectangle(frame, (x,y), (x+w,y+h), (255,0,0), 2)\n",
    "                    cv2.putText(frame, str(speeds_frame[i]), (x,y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 3)\n",
    "                cv2.imshow(video, frame)\n",
    "                cv2.waitKey(100)            \n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sname = 'C:/RoadCrossingAssistant/Data/Speeds_RetinaNet/speeds1.npy'\n",
    "#visualize_speeds_video(vname, fname, sname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_video(video, detection_array):\n",
    "\n",
    "    cap = cv2.VideoCapture(video)\n",
    "    cv2.namedWindow(video, cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(video, height=650, width=1156)\n",
    "    no_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    detection_array = np.load(detection_array, allow_pickle=True)\n",
    "\n",
    "    frame_count = -1\n",
    "\n",
    "    while(cap.isOpened()):\n",
    "\n",
    "        success,frame = cap.read()\n",
    "        #print(i)\n",
    "\n",
    "        if success == True:\n",
    "\n",
    "            if(frame_count == -1):\n",
    "                while True:\n",
    "\n",
    "                    key_init = cv2.waitKey(25)\n",
    "                    cv2.imshow(video, frame)\n",
    "\n",
    "                    if key_init == ord('a'):\n",
    "                        break\n",
    "\n",
    "            frame_count = frame_count + 1\n",
    "\n",
    "            temp = detection_array[frame_count]\n",
    "            boxes_frame = [(b[0],b[1],b[2]-b[0],b[3]-b[1]) for b in temp]\n",
    "            print(\"frame: \", frame_count)\n",
    "            no_boxes = len(boxes_frame)\n",
    "                \n",
    "            \n",
    "            for i in range(no_boxes):\n",
    "                box = boxes_frame[i]\n",
    "                (x,y,w,h) = [int(v) for v in box]\n",
    "                cv2.rectangle(frame, (x,y), (x+w,y+h), (255,0,0), 2)\n",
    "    \n",
    "            cv2.imshow(video, frame)\n",
    "            cv2.waitKey(100)            \n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "frame:  0\n",
      "frame:  1\n",
      "frame:  2\n",
      "frame:  3\n",
      "frame:  4\n",
      "frame:  5\n",
      "frame:  6\n",
      "frame:  7\n",
      "frame:  8\n",
      "frame:  9\n",
      "frame:  10\n",
      "frame:  11\n",
      "frame:  12\n",
      "frame:  13\n",
      "frame:  14\n",
      "frame:  15\n",
      "frame:  16\n",
      "frame:  17\n",
      "frame:  18\n",
      "frame:  19\n",
      "frame:  20\n",
      "frame:  21\n",
      "frame:  22\n",
      "frame:  23\n",
      "frame:  24\n",
      "frame:  25\n",
      "frame:  26\n",
      "frame:  27\n",
      "frame:  28\n",
      "frame:  29\n",
      "frame:  30\n",
      "frame:  31\n",
      "frame:  32\n",
      "frame:  33\n",
      "frame:  34\n",
      "frame:  35\n",
      "frame:  36\n",
      "frame:  37\n",
      "frame:  38\n",
      "frame:  39\n",
      "frame:  40\n",
      "frame:  41\n",
      "frame:  42\n",
      "frame:  43\n",
      "frame:  44\n",
      "frame:  45\n",
      "frame:  46\n",
      "frame:  47\n",
      "frame:  48\n",
      "frame:  49\n",
      "frame:  50\n",
      "frame:  51\n",
      "frame:  52\n",
      "frame:  53\n",
      "frame:  54\n",
      "frame:  55\n",
      "frame:  56\n",
      "frame:  57\n",
      "frame:  58\n",
      "frame:  59\n",
      "frame:  60\n",
      "frame:  61\n",
      "frame:  62\n",
      "frame:  63\n",
      "frame:  64\n",
      "frame:  65\n",
      "frame:  66\n",
      "frame:  67\n",
      "frame:  68\n",
      "frame:  69\n",
      "frame:  70\n",
      "frame:  71\n",
      "frame:  72\n",
      "frame:  73\n",
      "frame:  74\n",
      "frame:  75\n",
      "frame:  76\n",
      "frame:  77\n",
      "frame:  78\n",
      "frame:  79\n",
      "frame:  80\n",
      "frame:  81\n",
      "frame:  82\n",
      "frame:  83\n",
      "frame:  84\n",
      "frame:  85\n",
      "frame:  86\n",
      "frame:  87\n",
      "frame:  88\n",
      "frame:  89\n",
      "frame:  90\n",
      "frame:  91\n",
      "frame:  92\n",
      "frame:  93\n",
      "frame:  94\n",
      "frame:  95\n",
      "frame:  96\n",
      "frame:  97\n",
      "frame:  98\n",
      "frame:  99\n",
      "frame:  100\n",
      "frame:  101\n",
      "frame:  102\n",
      "frame:  103\n",
      "frame:  104\n",
      "frame:  105\n",
      "frame:  106\n",
      "frame:  107\n",
      "frame:  108\n",
      "frame:  109\n",
      "frame:  110\n",
      "frame:  111\n",
      "frame:  112\n",
      "frame:  113\n",
      "frame:  114\n",
      "frame:  115\n",
      "frame:  116\n",
      "frame:  117\n",
      "frame:  118\n",
      "frame:  119\n",
      "frame:  120\n",
      "frame:  121\n",
      "frame:  122\n",
      "frame:  123\n",
      "frame:  124\n",
      "frame:  125\n",
      "frame:  126\n",
      "frame:  127\n",
      "frame:  128\n",
      "frame:  129\n",
      "frame:  130\n",
      "frame:  131\n",
      "frame:  132\n",
      "frame:  133\n",
      "frame:  134\n",
      "frame:  135\n",
      "frame:  136\n",
      "frame:  137\n",
      "frame:  138\n",
      "frame:  139\n",
      "frame:  140\n",
      "frame:  141\n",
      "frame:  142\n",
      "frame:  143\n",
      "frame:  144\n",
      "frame:  145\n",
      "frame:  146\n",
      "frame:  147\n",
      "frame:  148\n",
      "frame:  149\n",
      "frame:  150\n",
      "frame:  151\n",
      "frame:  152\n",
      "frame:  153\n",
      "frame:  154\n",
      "frame:  155\n",
      "frame:  156\n",
      "frame:  157\n",
      "frame:  158\n",
      "frame:  159\n",
      "frame:  160\n",
      "frame:  161\n",
      "frame:  162\n",
      "frame:  163\n",
      "frame:  164\n",
      "frame:  165\n",
      "frame:  166\n",
      "frame:  167\n",
      "frame:  168\n",
      "frame:  169\n",
      "frame:  170\n",
      "frame:  171\n",
      "frame:  172\n",
      "frame:  173\n",
      "frame:  174\n",
      "frame:  175\n",
      "frame:  176\n",
      "frame:  177\n",
      "frame:  178\n",
      "frame:  179\n",
      "frame:  180\n",
      "frame:  181\n",
      "frame:  182\n",
      "frame:  183\n",
      "frame:  184\n",
      "frame:  185\n",
      "frame:  186\n",
      "frame:  187\n",
      "frame:  188\n",
      "frame:  189\n",
      "frame:  190\n",
      "frame:  191\n",
      "frame:  192\n",
      "frame:  193\n",
      "frame:  194\n",
      "frame:  195\n",
      "frame:  196\n",
      "frame:  197\n",
      "frame:  198\n",
      "frame:  199\n",
      "frame:  200\n",
      "frame:  201\n",
      "frame:  202\n",
      "frame:  203\n",
      "frame:  204\n",
      "frame:  205\n",
      "frame:  206\n",
      "frame:  207\n",
      "frame:  208\n",
      "frame:  209\n"
     ]
    }
   ],
   "source": [
    "visualize_video(vname, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(210,)\n[list([[1408, 531, 1451, 614], [1284, 478, 1373, 575], [1340, 519, 1426, 640], [1525, 536, 1692, 693], [1121, 534, 1297, 719], [1519, 460, 1821, 713], [11, 263, 623, 607], [1677, 546, 1905, 1048]])\n list([[1415, 527, 1462, 588], [1275, 484, 1374, 577], [1326, 516, 1427, 643], [1099, 534, 1286, 723], [1520, 458, 1825, 720], [38, 263, 651, 607], [1678, 549, 1904, 1048]])\n list([[933, 472, 1025, 534], [1419, 494, 1470, 568], [1414, 527, 1464, 588], [1279, 479, 1386, 577], [1319, 527, 1418, 646], [1519, 536, 1687, 699], [1509, 457, 1897, 715], [1074, 542, 1283, 727], [60, 277, 688, 604], [1675, 547, 1904, 1047]])\n list([[934, 472, 1026, 534], [1422, 481, 1474, 538], [1414, 487, 1472, 574], [1290, 478, 1400, 584], [1292, 481, 1392, 587], [1358, 488, 1469, 592], [1413, 494, 1475, 589], [1300, 490, 1450, 626], [1307, 519, 1407, 647], [1053, 545, 1251, 733], [1512, 458, 1824, 726], [97, 278, 706, 611], [1673, 546, 1904, 1047]])\n list([[42, 352, 148, 514], [42, 353, 147, 515], [1401, 486, 1479, 589], [1299, 519, 1397, 648], [1513, 455, 1820, 726], [1024, 543, 1241, 737], [131, 280, 728, 615], [1675, 548, 1905, 1048]])\n list([[40, 354, 169, 514], [1386, 488, 1480, 588], [1501, 484, 1608, 611], [1286, 510, 1390, 649], [999, 539, 1222, 743], [165, 280, 768, 604], [1675, 548, 1906, 1045]])\n list([[40, 354, 202, 512], [1378, 487, 1485, 588], [1273, 526, 1381, 653], [969, 537, 1199, 746], [183, 282, 788, 601], [1669, 545, 1901, 1044]])\n list([[40, 353, 227, 512], [1371, 485, 1490, 589], [1259, 522, 1369, 655], [40, 349, 227, 512], [1505, 525, 1687, 719], [936, 557, 1178, 749], [215, 276, 802, 610], [1669, 549, 1901, 1044]])\n list([[39, 353, 253, 513], [1384, 489, 1492, 586], [1485, 485, 1598, 615], [1486, 487, 1594, 629], [1249, 519, 1362, 657], [43, 350, 251, 515], [897, 554, 1159, 755], [225, 278, 840, 597], [1671, 550, 1900, 1044]])\n list([[1358, 485, 1490, 587], [1417, 486, 1542, 598], [1482, 483, 1596, 613], [1235, 512, 1357, 659], [40, 352, 287, 515], [868, 553, 1134, 763], [263, 284, 865, 598], [1671, 554, 1900, 1045]])\n list([[1351, 483, 1483, 589], [1472, 484, 1595, 611], [1224, 502, 1349, 662], [40, 356, 310, 517], [890, 448, 1082, 724], [1485, 478, 1735, 729], [835, 543, 1114, 769], [285, 286, 888, 597], [1668, 551, 1900, 1046]])\n list([[1347, 476, 1479, 588], [1470, 482, 1591, 619], [1209, 513, 1345, 665], [40, 356, 320, 519], [36, 355, 322, 518], [800, 547, 1086, 777], [313, 291, 893, 606], [1668, 552, 1900, 1045]])\n list([[1351, 489, 1478, 586], [1466, 485, 1585, 625], [1196, 520, 1328, 667], [42, 356, 318, 520], [38, 354, 321, 520], [820, 446, 1029, 744], [747, 526, 1073, 778], [339, 288, 901, 605], [1669, 550, 1903, 1047]])\n list([[1355, 490, 1463, 587], [1376, 490, 1526, 596], [1460, 490, 1579, 622], [1179, 511, 1325, 672], [41, 358, 319, 521], [37, 356, 324, 521], [792, 436, 987, 741], [1473, 505, 1737, 730], [716, 532, 1039, 788], [357, 286, 900, 604], [1667, 549, 1903, 1047]])\n list([[1355, 486, 1455, 585], [1394, 487, 1530, 598], [1445, 489, 1575, 621], [1166, 515, 1312, 675], [37, 358, 323, 522], [409, 306, 872, 623], [1459, 454, 1815, 731], [676, 534, 1020, 796], [1668, 550, 1903, 1045]])]\n"
     ]
    }
   ],
   "source": [
    "detection_array = np.load(fname, allow_pickle=True)\n",
    "print(detection_array.shape)\n",
    "print(detection_array[:15])"
   ]
  }
 ]
}