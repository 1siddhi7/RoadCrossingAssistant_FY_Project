{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit ('roadcross': conda)",
   "metadata": {
    "interpreter": {
     "hash": "efbaad368bcd49cf5b8b1d4bc08527738fe3c05d47d6e3ea110540aa6c36949d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#importing required libraries\n",
    "import glob\n",
    "from imageai.Detection import VideoObjectDetection\n",
    "import natsort\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from imageai.Detection import VideoObjectDetection\n",
    "import os\n",
    "import sys\n",
    "from random import randint\n",
    "from math import ceil, nan, sqrt\n",
    "import natsort\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sys\n",
    "import cv2\n",
    "from random import randint\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numbers_from_filename(filename):\n",
    "    'utility function to get first number from a file name'\n",
    "    return re.search(r'\\d+', filename).group(0)\n",
    "\n",
    "trackerTypes = ['BOOSTING', 'MIL', 'KCF','TLD', 'MEDIANFLOW', 'GOTURN', 'MOSSE', 'CSRT']\n",
    "\n",
    "def createTrackerByName(trackerType):\n",
    "    \n",
    "  # Create a tracker based on tracker name\n",
    "    if trackerType == trackerTypes[0]:\n",
    "        tracker = cv2.TrackerBoosting_create()\n",
    "  \n",
    "    elif trackerType == trackerTypes[1]: \n",
    "        tracker = cv2.TrackerMIL_create()\n",
    "   \n",
    "    elif trackerType == trackerTypes[2]:\n",
    "        tracker = cv2.TrackerKCF_create()\n",
    "  \n",
    "    elif trackerType == trackerTypes[3]:\n",
    "        tracker = cv2.TrackerTLD_create()\n",
    "   \n",
    "    elif trackerType == trackerTypes[4]:\n",
    "        tracker = cv2.TrackerMedianFlow_create()\n",
    "    \n",
    "    elif trackerType == trackerTypes[5]:\n",
    "        tracker = cv2.TrackerGOTURN_create()\n",
    "            \n",
    "    elif trackerType == trackerTypes[6]:\n",
    "        tracker = cv2.TrackerMOSSE_create()\n",
    "        \n",
    "    elif trackerType == trackerTypes[7]:\n",
    "        tracker = cv2.TrackerCSRT_create()\n",
    "        \n",
    "    else:\n",
    "        tracker = None\n",
    "        print('Incorrect tracker name')\n",
    "        print('Available trackers are:')\n",
    "        for t in trackerTypes:\n",
    "            print(t)\n",
    "     \n",
    "    return tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speeds_from_frame(video, boxes_list, frame_no, no_previous_frames, trackerType = \"KCF\"):\n",
    "\n",
    "    '''\n",
    "    Detects speed of each vehicle in the frame and returns and an containing these speeds\n",
    "\n",
    "    Parameters:\n",
    "    video(string) : path of the video\n",
    "    frame_no : frame no of the video for which you require directions\n",
    "    boxes_list(list) : list containing bounding boxes for all detected vehicles in the particular frame\n",
    "    no_previous_frames(int) : number of previous frames to be considered while calculating the speed\n",
    "    trackerType(string) : the openCV tracker type to be used\n",
    "\n",
    "    '''\n",
    "    frame_buffer = []\n",
    "    #cv2.namedWindow(video, cv2.WINDOW_NORMAL)\n",
    "    #cv2.resizeWindow(video, height=650, width=1156)\n",
    "    cap = cv2.VideoCapture(video)\n",
    "\n",
    "    for i in range(frame_no - no_previous_frames, frame_no + 1):\n",
    "\n",
    "        cap.set(1,i)\n",
    "        ret, frame = cap.read()\n",
    "        frame_buffer.append(frame)\n",
    "\n",
    "    multiTracker_back = cv2.MultiTracker_create()\n",
    "    #multiTracker = cv2.MultiTracker_create()\n",
    "    n = len(boxes_list)\n",
    "    speeds = [0]*n\n",
    "    x1 = [0]*n  #x coordinates of vehicles in frame_no\n",
    "    y1 = [0]*n #y coordinates of vehicles in frame_no\n",
    "    x2 = [0]*n  #x coordinates of vehicles in frame_no - no_previous_frames\n",
    "    y2 = [0]*n #y coordinates of vehicles in frame_no - no_previous_frames\n",
    "\n",
    "    frame = frame_buffer.pop()\n",
    "    for i in range(n):\n",
    "        box = boxes_list[i]\n",
    "        x1[i] = (box[0]+2*box[2])/2\n",
    "        y1[i] = (box[1]+2*box[3])/2\n",
    "        multiTracker_back.add(createTrackerByName(trackerType), frame, box)\n",
    "        #all the vehicles from boxes_list added in the traker instance\n",
    "        #applying vehicle tracking in backward direction\n",
    "    for j in range(no_previous_frames):\n",
    "        frame = frame_buffer.pop()\n",
    "        (success_back, boxes_back) = multiTracker_back.update(frame)\n",
    "\n",
    "    for i in range(n):\n",
    "        b = boxes_back[i]\n",
    "        x2[i] = (b[0]+2*b[2])/2\n",
    "        y2[i] = (b[1]+2*b[3])/2\n",
    "        x_d = x2[i] - x1[i]\n",
    "        y_d = y2[i] - y1[i]\n",
    "        dist = (x_d**2 + y_d**2)**0.5\n",
    "        speeds[i] = dist\n",
    "\n",
    "    return np.array(speeds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speeds_from_video(video, detection_array, target_folder, no_previous_frames = 6):\n",
    "\n",
    "    '''\n",
    "    Detects speed of each vehicle in each frame of the video and returns and an containing these speeds\n",
    "\n",
    "    Parameters:\n",
    "    video(string) : path of the video\n",
    "    detection_array(string) : path of the detection_array\n",
    "    target_folder(string) : path of the folder where you want to store the array of speeds\n",
    "    no_previous_frames(int) : number of previous frames to be considered while calculating the speed\n",
    "\n",
    "    '''\n",
    "\n",
    "    boxes_array = np.load(detection_array, allow_pickle=True)\n",
    "    no_frames = boxes_array.shape[0]\n",
    "    print(\"no_frames: \", no_frames)\n",
    "    findex = get_numbers_from_filename(video)\n",
    "    S = []\n",
    "    for i in range(no_previous_frames):\n",
    "        S.append([])\n",
    "\n",
    "    for frame_no in range(no_previous_frames, no_frames):\n",
    "        print(\"processing frame_no: \", frame_no)\n",
    "\n",
    "        temp = boxes_array[frame_no]\n",
    "        boxes_list = [(b[0],b[1],b[2]-b[0],b[3]-b[1]) for b in temp]\n",
    "\n",
    "        speeds = get_speeds_from_frame(video, boxes_list, frame_no, no_previous_frames)\n",
    "        S.append(speeds)\n",
    "            \n",
    "    S = np.array(S)\n",
    "    print('saving speeds for video' + video)\n",
    "    np.save(target_folder+'speeds'+str(findex),S)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "videos_folder = \"C:/RoadCrossingAssistant/Data/Videos/\"\n",
    "videos = glob.glob(videos_folder+'video*.MOV')\n",
    "videos = natsort.natsorted(videos)\n",
    "arrays_folder = \"C:/RoadCrossingAssistant/Data/Arrays_RetinaNet/\"\n",
    "arrays = glob.glob(arrays_folder+'array*.npy')\n",
    "arrays = natsort.natsorted(arrays)\n",
    "target_folder = \"C:/RoadCrossingAssistant/Data/Speeds_RetinaNet/\"\n",
    "\n",
    "for (vname,aname) in zip(videos,arrays):\n",
    "    print(\"starting for {} \\n\" .format(vname))\n",
    "    get_speeds_from_video(vname, aname, target_folder)\n",
    "    print(\"----------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_speeds_video(video, detection_array, speeds_array):\n",
    "\n",
    "    '''\n",
    "    Visualize calculated speeds for the video (press a to start the display of visualization in the opencv window)\n",
    "\n",
    "    Parameters:\n",
    "    video(string) : path of the video\n",
    "    detection_array(string) : path of the detection_array\n",
    "    speeds_array(string) : path of the speeed array\n",
    "\n",
    "    '''\n",
    "    cap = cv2.VideoCapture(video)\n",
    "    cv2.namedWindow(video, cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(video, height=650, width=1156)\n",
    "    no_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    detection_array = np.load(detection_array, allow_pickle=True)\n",
    "    speeds_array = np.load(speeds_array,allow_pickle=True)\n",
    "\n",
    "    frame_count = -1\n",
    "\n",
    "    while(cap.isOpened()):\n",
    "\n",
    "        success,frame = cap.read()\n",
    "        key = cv2.waitKey(100)\n",
    "        #print(i)\n",
    "\n",
    "        if success == True:\n",
    "\n",
    "            if(frame_count == -1):\n",
    "                while True:\n",
    "\n",
    "                    key_init = cv2.waitKey(25)\n",
    "                    cv2.imshow(video, frame)\n",
    "\n",
    "                    if key_init == ord('a'):\n",
    "                        break\n",
    "\n",
    "            frame_count = frame_count + 1\n",
    "\n",
    "            speeds_frame = speeds_array[frame_count]\n",
    "            temp = detection_array[frame_count]\n",
    "            boxes_frame = [(b[0],b[1],b[2]-b[0],b[3]-b[1]) for b in temp]\n",
    "            no_boxes = len(boxes_frame)\n",
    "\n",
    "            if(frame_count < 6):\n",
    "\n",
    "                for i in range(no_boxes):\n",
    "                    box = boxes_frame[i]\n",
    "                    (x,y,w,h) = [int(v) for v in box]\n",
    "                    cv2.rectangle(frame, (x,y), (x+w,y+h), (255,0,0), 2)\n",
    "\n",
    "                cv2.imshow(video, frame)\n",
    "                cv2.waitKey(100)        \n",
    "\n",
    "            else:\n",
    "                if(len(speeds_frame) != len(boxes_frame)):\n",
    "                    raise Exception(\"mismatch in length of speeds_frame and boxes_frame\")\n",
    "                \n",
    "                for i in range(no_boxes):\n",
    "                    box = boxes_frame[i]\n",
    "                    (x,y,w,h) = [int(v) for v in box]\n",
    "                    s = round(speeds_frame[i], 2)\n",
    "                    cv2.rectangle(frame, (x,y), (x+w,y+h), (255,0,0), 2)\n",
    "                    cv2.putText(frame, str(s), (x,y), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 3)\n",
    "                cv2.imshow(video, frame)\n",
    "\n",
    "                if key == ord('p'): # pause a video\n",
    "\n",
    "                    while True:\n",
    "                        \n",
    "                        key2 = cv2.waitKey(33)\n",
    "                        cv2.imshow(video, frame)\n",
    "                        \n",
    "                        if key2 == ord('p'): # resume video after pausing\n",
    "                            break\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vname = 'C:/RoadCrossingAssistant/Data/Videos/video64.MOV'\n",
    "aname = 'C:/RoadCrossingAssistant/Data/Arrays_RetinaNet/array64.npy'\n",
    "sname = 'C:/RoadCrossingAssistant/Data/Speeds_RetinaNet/speeds64.npy'\n",
    "visualize_speeds_video(vname, aname, sname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extra........\n",
    "def visualize_video(video, detection_array):\n",
    "\n",
    "    cap = cv2.VideoCapture(video)\n",
    "    cv2.namedWindow(video, cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(video, height=650, width=1156)\n",
    "    no_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    detection_array = np.load(detection_array, allow_pickle=True)\n",
    "\n",
    "    frame_count = -1\n",
    "\n",
    "    while(cap.isOpened()):\n",
    "\n",
    "        success,frame = cap.read()\n",
    "        key = cv2.waitKey(34)\n",
    "        #print(i)\n",
    "\n",
    "        if success == True:\n",
    "\n",
    "            if(frame_count == -1):\n",
    "                while True:\n",
    "\n",
    "                    key_init = cv2.waitKey(25)\n",
    "                    cv2.imshow(video, frame)\n",
    "\n",
    "                    if key_init == ord('a'):\n",
    "                        break\n",
    "\n",
    "            if key == ord('p'): # pause a video\n",
    "\n",
    "                while True:\n",
    "                    \n",
    "                    key2 = cv2.waitKey(33)\n",
    "                    cv2.imshow(video, frame)\n",
    "                    \n",
    "                    if key2 == ord('p'): # resume video after pausing\n",
    "                        break\n",
    "\n",
    "            frame_count = frame_count + 1\n",
    "\n",
    "            temp = detection_array[frame_count]\n",
    "            boxes_frame = [(b[0],b[1],b[2]-b[0],b[3]-b[1]) for b in temp]\n",
    "            print(\"frame: \", frame_count)\n",
    "            no_boxes = len(boxes_frame)\n",
    "                \n",
    "            \n",
    "            for i in range(no_boxes):\n",
    "                box = boxes_frame[i]\n",
    "                (x,y,w,h) = [int(v) for v in box]\n",
    "                cv2.rectangle(frame, (x,y), (x+w,y+h), (255,0,0), 2)\n",
    "    \n",
    "            cv2.imshow(video, frame)\n",
    "            cv2.waitKey(100)            \n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_video(vname, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "detection_array = np.load(fname, allow_pickle=True)\n",
    "print(detection_array.shape)\n",
    "print(detection_array[:15])"
   ]
  }
 ]
}