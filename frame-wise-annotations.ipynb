{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import csv\n",
    "import glob\n",
    "import natsort\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numbers_from_filename(filename):\n",
    "    return re.search(r'\\d+', filename).group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def markSafeDurationForVideo(video_path):\n",
    "\n",
    "    '''\n",
    "    generates a list that contains safe duration(s) for video\n",
    "\n",
    "    arguments:\n",
    "    video_path(string) - video path for every video\n",
    "\n",
    "    returns:\n",
    "    safe_duration_list(list) - list containing safe duration start and safe duration end for the video     flag(boolean) - flag to indicate whether video is annotated successfully or not\n",
    "    '''\n",
    "\n",
    "    # fore resizing a window for video (optional depending on screen size)\n",
    "    cv2.namedWindow(video_path, cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(video_path, height=760, width=1366)\n",
    "\n",
    "    # setting font properties for displaying frame number with video\n",
    "    font = cv2.FONT_HERSHEY_COMPLEX  # fontFace\n",
    "    fontScale = 1  # fontScale\n",
    "    fontColor = (255,255,255) # fontColor\n",
    "    lineType = 2 # lineType\n",
    "    \n",
    "    # capture a video from given path\n",
    "    scanned_video = cv2.VideoCapture(video_path)\n",
    "    no_frames = int(scanned_video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    frame_count = -1\n",
    "    flag = 1\n",
    "\n",
    "    ss = []  # safe duration start list\n",
    "    se = [] # safe duration end list\n",
    "    safe_duration_list = [] # final list containing ss and se\n",
    "\n",
    "    if (scanned_video.isOpened()== False): # check if there is error in opening a video\n",
    "        raise Exception(\"check the videopath or error opening video\")\n",
    "\n",
    "    while(scanned_video.isOpened()):\n",
    "\n",
    "        ret, frame = scanned_video.read() \n",
    "        key = cv2.waitKey(33)\n",
    "        \n",
    "        if(ret == True):\n",
    "\n",
    "            if(frame_count == -1):\n",
    "                while True:\n",
    "\n",
    "                    key_init = cv2.waitKey(33)\n",
    "                    cv2.putText(frame, \"Frame Number:\" + str(frame_count), org=(20,50), fontFace=font, fontScale=fontScale, color=fontColor, lineType=lineType, thickness=3)\n",
    "                    cv2.imshow(video_path, frame)\n",
    "\n",
    "                    if key_init == ord('a'):  # to start a video when the video is loaded\n",
    "                        break\n",
    "            \n",
    "            frame_count = frame_count + 1\n",
    "            \n",
    "            cv2.putText(frame, \"Frame Number:\" + str(frame_count), org=(20,50), fontFace=font, fontScale=fontScale, color=fontColor, lineType=lineType, thickness=3)\n",
    "            cv2.imshow(video_path,frame)\n",
    "\n",
    "            if key == ord('p'): # pause a video\n",
    "\n",
    "                while True:\n",
    "                    \n",
    "                    key2 = cv2.waitKey(33)\n",
    "\n",
    "                    cv2.putText(frame, \"Frame Number:\" + str(frame_count), org=(20,50), fontFace=font, fontScale=fontScale, color=fontColor, lineType=lineType, thickness=3)\n",
    "                    cv2.imshow(video_path, frame)\n",
    "                    \n",
    "                    if key2 == ord('p'): # resume video after pausing\n",
    "                        break\n",
    "            \n",
    "            if key == ord('r'): # key for the case when there is safe duration at the 0th frame(at the very start of the video)\n",
    "\n",
    "                ss.append(0) # add 0th frame in list of safe duration start\n",
    "                if (len(ss) != 1):\n",
    "                    print(\"You have made some mistake\")\n",
    "                    flag = 0\n",
    "                    break\n",
    "                    \n",
    "                safe_duration_list.append(0)\n",
    "            \n",
    "            if key == ord('s'): # save safe duration start\n",
    "\n",
    "                ss.append(frame_count)\n",
    "                if (len(ss) != len(se) + 1):\n",
    "                    print(\"You have made some mistake\")\n",
    "                    flag = 0\n",
    "                    break\n",
    "                    \n",
    "                safe_duration_list.append(frame_count)\n",
    "                \n",
    "            if key == ord('e'): # save safe duration end\n",
    "\n",
    "                se.append(frame_count)\n",
    "                if (len(se) != len(ss)):\n",
    "                    print(\"You have made some mistake\")\n",
    "                    flag = 0\n",
    "                    break\n",
    "                safe_duration_list.append(frame_count)\n",
    "            \n",
    "            if key == ord('q'): # close video window\n",
    "                break\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "\n",
    "    scanned_video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # if length of safe duration list is odd length, i.e. one safe duration end is left to be appended,      so add last frame of the video as safe duration end.\n",
    "    if(len(safe_duration_list) % 2 !=0):\n",
    "        safe_duration_list.append(no_frames - 1)\n",
    "    \n",
    "    return safe_duration_list, flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_labels_csv(videos_list, csv_file, pickle_list_path):\n",
    "\n",
    "    '''\n",
    "    saves labels of safe durations from the videos into csv file\n",
    "\n",
    "    arguments:\n",
    "    videos_list(list) - list of all videos path stored as string\n",
    "    csv_file(string) - path for csv file\n",
    "    pickle_list_path - path for array pickle file\n",
    "\n",
    "    '''\n",
    "    \n",
    "    csv_writer = csv.writer(open(csv_file,\"w\"))\n",
    "    open_file = open(pickle_list_path, \"rb\")\n",
    "    pickle_list = pickle.load(open_file)\n",
    "    open_file.close()\n",
    "    \n",
    "    for video_path in videos_list:\n",
    "        \n",
    "        print('\\nstarting for', video_path)\n",
    "        video_no = int(get_numbers_from_filename(video_path)) # function for getting video number for current video\n",
    "        ready_flag = str.lower(input('type \"y\" if you are ready to annotate the video and \"n\" to quit the program\\n'))\n",
    "        if(ready_flag == 'y'):\n",
    "            correct_flag = 1\n",
    "            surity_flag = 0\n",
    "            while(surity_flag == 0 or correct_flag == 0): # loop through the video untill surity and correct flag is not valid\n",
    "                safe_duration_list, correct_flag = markSafeDurationForVideo(video_path)\n",
    "                if(correct_flag == 0):\n",
    "                    print(\"press keys carefully this time!\")\n",
    "                    input(\"press any key when you are ready\")\n",
    "                else:\n",
    "                    surity_flag = int(input('Enter 0 to repeat the annotations process and 1 to proceed to next video\\n')) # for assuring that video is annotated as per needed by user\n",
    "                if(surity_flag == 1 and correct_flag == 1):\n",
    "                    break\n",
    "\n",
    "            #csv_writer.writerow(safe_duration_list)\n",
    "            pickle_list[video_no-1] = safe_duration_list # add list to pickle file with video number as index\n",
    "\n",
    "            print(\"safe_duration_list\", safe_duration_list)\n",
    "            print('------------------------------------------')\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            print('\\nTake a break! You must be tired')\n",
    "            break\n",
    "            \n",
    "    open_file = open(pickle_list_path, \"wb\")\n",
    "    pickle.dump(pickle_list, open_file)\n",
    "    open_file.close()\n",
    "    csv_writer.writerows(pickle_list)\n",
    "    print(\"list and csv file saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "starting for /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/videos/video81.MOV\n",
      "safe_duration_list [0, 94, 138, 257, 319, 394]\n",
      "------------------------------------------\n",
      "\n",
      "starting for /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/videos/video82.MOV\n",
      "safe_duration_list [0, 87, 345, 448]\n",
      "------------------------------------------\n",
      "\n",
      "starting for /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/videos/video83.MOV\n",
      "safe_duration_list [165, 375]\n",
      "------------------------------------------\n",
      "\n",
      "starting for /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/videos/video84.MOV\n",
      "safe_duration_list [100, 151, 212, 331, 554, 611, 668, 749]\n",
      "------------------------------------------\n",
      "\n",
      "starting for /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/videos/video85.MOV\n",
      "safe_duration_list [15, 104, 156, 226, 281, 490]\n",
      "------------------------------------------\n",
      "\n",
      "starting for /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/videos/video86.MOV\n",
      "safe_duration_list [12, 221]\n",
      "------------------------------------------\n",
      "\n",
      "starting for /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/videos/video87.MOV\n",
      "safe_duration_list [117, 169, 228, 294, 394, 482]\n",
      "------------------------------------------\n",
      "\n",
      "starting for /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/videos/video88.MOV\n",
      "safe_duration_list [0, 76, 157, 280, 430, 509]\n",
      "------------------------------------------\n",
      "\n",
      "starting for /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/videos/video89.MOV\n",
      "safe_duration_list [168, 270]\n",
      "------------------------------------------\n",
      "\n",
      "starting for /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/videos/video90.MOV\n",
      "safe_duration_list [97, 188, 284, 325, 362, 461, 496, 569]\n",
      "------------------------------------------\n",
      "\n",
      "starting for /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/videos/video91.MOV\n",
      "safe_duration_list [0, 94, 362, 426]\n",
      "------------------------------------------\n",
      "\n",
      "starting for /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/videos/video92.MOV\n",
      "safe_duration_list [276, 321, 357, 419]\n",
      "------------------------------------------\n",
      "\n",
      "starting for /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/videos/video93.MOV\n",
      "safe_duration_list [0, 46, 67, 186]\n",
      "------------------------------------------\n",
      "\n",
      "starting for /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/videos/video94.MOV\n",
      "safe_duration_list [16, 53, 211, 260, 284, 329]\n",
      "------------------------------------------\n",
      "\n",
      "starting for /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/videos/video95.MOV\n",
      "safe_duration_list [10, 85, 144, 191, 271, 334]\n",
      "------------------------------------------\n",
      "\n",
      "starting for /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/videos/video96.MOV\n",
      "safe_duration_list [15, 106, 279, 419]\n",
      "------------------------------------------\n",
      "\n",
      "starting for /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/videos/video97.MOV\n",
      "safe_duration_list [0, 159, 243, 389]\n",
      "------------------------------------------\n",
      "\n",
      "starting for /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/videos/video98.MOV\n",
      "safe_duration_list []\n",
      "------------------------------------------\n",
      "\n",
      "starting for /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/videos/video99.MOV\n",
      "safe_duration_list [37, 253, 300, 360]\n",
      "------------------------------------------\n",
      "\n",
      "starting for /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/videos/video100.MOV\n",
      "safe_duration_list [0, 69, 132, 193, 268, 411]\n",
      "------------------------------------------\n",
      "\n",
      "starting for /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/videos/video101.MOV\n",
      "safe_duration_list [246, 289, 324, 370]\n",
      "------------------------------------------\n",
      "\n",
      "starting for /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/videos/video102.MOV\n",
      "safe_duration_list [0, 103, 132, 239]\n",
      "------------------------------------------\n",
      "\n",
      "starting for /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/videos/video103.MOV\n",
      "safe_duration_list [79, 158, 197, 312]\n",
      "------------------------------------------\n",
      "\n",
      "starting for /home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/videos/video104.MOV\n",
      "safe_duration_list [0, 147, 174, 239]\n",
      "------------------------------------------\n",
      "list and csv file saved\n"
     ]
    }
   ],
   "source": [
    "video_folder = '/home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/videos'\n",
    "video_list = glob.glob(video_folder + '/video*.MOV')\n",
    "video_list = (natsort.natsorted(video_list))[80:]\n",
    "pickle_list_path = '/home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/labels_framewise.pkl'\n",
    "# video_list = ['/home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/videos_train/video1.MOV']\n",
    "\n",
    "csv_file = '/home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/labels-frame-wise.csv'\n",
    "\n",
    "save_labels_csv(video_list, csv_file, pickle_list_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "104 \n [[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [70, 139], [0, 54], [16, 179], [0, 56, 103, 161], [], [24, 94, 140, 179], [21, 98], [134, 179], [69, 109], [66, 95, 117, 179], [], [129, 179], [34, 65], [], [], [0, 209], [208, 274], [0, 50, 170, 302, 366, 479], [0, 54, 108, 183, 234, 343], [32, 59, 273, 389], [0, 94, 138, 257, 319, 394], [0, 87, 345, 448], [165, 375], [100, 151, 212, 331, 554, 611, 668, 749], [15, 104, 156, 226, 281, 490], [12, 221], [117, 169, 228, 294, 394, 482], [0, 76, 157, 280, 430, 509], [168, 270], [97, 188, 284, 325, 362, 461, 496, 569], [0, 94, 362, 426], [276, 321, 357, 419], [0, 46, 67, 186], [16, 53, 211, 260, 284, 329], [10, 85, 144, 191, 271, 334], [15, 106, 279, 419], [0, 159, 243, 389], [], [37, 253, 300, 360], [0, 69, 132, 193, 268, 411], [246, 289, 324, 370], [0, 103, 132, 239], [79, 158, 197, 312], [0, 147, 174, 239]]\n"
     ]
    }
   ],
   "source": [
    "#labels_framewise = [[] for i in range(104)]\n",
    "file_name = \"/home/yagnesh/Study/Machine Learning/ML projects/RoadCrossingAssistant_Arrays/labels_framewise.pkl\"\n",
    "\n",
    "#open_file = open(file_name, \"wb\")\n",
    "#pickle.dump(labels_framewise, open_file)\n",
    "#open_file.close()\n",
    "\n",
    "open_file = open(file_name, \"rb\")\n",
    "loaded_list = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "print(len(loaded_list),'\\n', loaded_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('roadcross': conda)",
   "language": "python",
   "name": "python37364bitroadcrossconda9373e858eb374c278c9e03a6646bb46c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}